import os
import pickle
import pandas as pd
import numpy as np
import streamlit as st
import streamlit_authenticator as stauth
from sklearn import metrics
from sklearn import preprocessing
from sklearn.impute import KNNImputer
import tensorflow as tf
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import GRU, LSTM, Dense, Input, Reshape
from tensorflow.keras.callbacks import EarlyStopping
import keras_tuner as kt
# å°†é¡µé¢æ”¾å¤§è‡³é€‚åº”webå®½åº¦
st.set_page_config(layout="wide")
# è®¾ç½®ç”¨æˆ·å’Œå¯†ç 
credentials = {'usernames': {
                'NKU': {'email': '593160536@qq.com',
                        'name': 'NKU', 'password': 'woshiainankaide'},
                'admin': {'email': 'likx@nankai.edu.cn',
                          'name': 'admin', 'password': 'admin'}}}
# è®¾ç½®ç™»å½•çª—å£
authenticator = stauth.Authenticate(credentials)
authenticator.login('main',
                    fields={'Form name': 'åŸºäºæ·±åº¦å­¦ä¹ æ¨¡å‹çš„æ°´å‚æ™ºæ…§åŠ è¯é¢„æµ‹ç³»ç»Ÿ',
                            'Username': 'ç”¨æˆ·å',
                            'Password': 'å¯†ç ',
                            'Login': 'ç™»å½•'})
# åˆ¤æ–­ç”¨æˆ·ç™»é™†çŠ¶æ€
if st.session_state['authentication_status']:
    col_a, col_b = st.columns(spec=[8, 1], vertical_alignment='bottom')
    with col_a:
        st.header('åŸºäºæ·±åº¦å­¦ä¹ æ¨¡å‹çš„æ°´å‚æ™ºæ…§åŠ è¯é¢„æµ‹ç³»ç»Ÿ')
    with col_b:
        authenticator.logout(button_name='é€€å‡ºç™»å½•')
elif st.session_state['authentication_status'] is False:
    st.error("ç”¨æˆ·åæˆ–å¯†ç ä¸æ­£ç¡®ï¼", icon="ğŸš¨")
    st.stop()
elif st.session_state['authentication_status'] is None:
    st.info('è¯·è¾“å…¥ç”¨æˆ·åå’Œå¯†ç ï¼', icon="â„¹ï¸")
    st.stop()
# å®šä¹‰æ£€æŸ¥Excelæ–‡ä»¶çš„å‡½æ•°ä»¥ä¾¿äºåç»­è°ƒç”¨
def check_sheet_exists(file_path, sheet_name):
    try:
        xls = pd.ExcelFile(file_path)
        sheet_names = xls.sheet_names
        if sheet_name in sheet_names:
            return True
        else:
            return False
    except:
        return False
# å®šä¹‰æ•°æ®å½¢å¼è½¬æ¢å‡½æ•°ä»¥ä¾¿äºåç»­æ·±åº¦å­¦ä¹ æ¨¡å‹çš„è®­ç»ƒ
def create_sequences(X, y, seq_length):
    X_seq, y_seq = [], []
    for i in range(len(X) - seq_length + 1):
        X_seq.append(X[i:i+seq_length])
        y_seq.append(y[i+seq_length-1])
    return np.array(X_seq), np.array(y_seq)
# å®šä¹‰æ–‡ä»¶å¤¹æ£€æŸ¥å‡½æ•°ä»¥ä¾¿äºè°ƒç”¨æ¨¡å‹
def check_folder_empty(folder_path):
    file_list = os.listdir(folder_path)
    if len(file_list) == 0:
        return False
    else:
        return True
# ç¬¬ä¸€éƒ¨åˆ†çš„ç¬¬ä¸€é¡µï¼šé¡¹ç›®èƒŒæ™¯åŠæ³¨æ„äº‹é¡¹
def page_11():
    with st.container(border=True):
        st.subheader('é¡¹ç›®èƒŒæ™¯')
        st.write('**ç®€ä»‹**ï¼šæœ¬é¡¹ç›®æ—¨åœ¨åˆ©ç”¨æ·±åº¦å­¦ä¹ æ¨¡å‹é©±åŠ¨æ°´å‚æŠ•è¯ç¯èŠ‚çš„æ™ºèƒ½åŒ–ç²¾å‡†æ§åˆ¶ï¼Œè¾¾åˆ°åŸæ°´æ°´è´¨ã€æ°´é‡å˜åŒ–çš„è‡ªé€‚åº”æœ€ä½³æŠ•è¯é‡é¢„æµ‹ï¼Œæå‡æ°´å‚è¿ç»´ç®¡æ§çš„æ™ºèƒ½åŒ–æ°´å¹³å’Œå¯é ç¨‹åº¦ã€‚')
        st.write('**ä¼˜åŠ¿**ï¼šé€šè¿‡æ·±åº¦å­¦ä¹ ç®—æ³•å®ç°å¤šè¾“å…¥å¤šè¾“å‡ºçš„é«˜è´¨é‡çš„é¢„æµ‹æ•ˆæœï¼Œå¯è§†åŒ–ç½‘é¡µæ“ä½œæ–¹ä¾¿ã€‚')
    with st.container(border=True):
        st.subheader('æ³¨æ„äº‹é¡¹')
        st.write('1. åœ¨**æ•°æ®ä¸Šä¼ **é¡µé¢ï¼Œä¸Šä¼ çš„æ–‡ä»¶æ ¼å¼åº”ä¸º.xlsæˆ–xlsxï¼›')
        st.write('2. æœ¬ç³»ç»Ÿä¸ºæ°´å‚ä¸­çš„æ—¶åºæ•°æ®æä¾›äº†ç®€ä¾¿å¿«æ·çš„é¢„æµ‹æ–¹æ³•ï¼Œè¯·åœ¨å¾…ä¸Šä¼ çš„Excelæ–‡ä»¶ä¸­æ˜ç¡®æŒ‡å‡ºæ—¶é—´åˆ—å¹¶å°†å…¶å‘½åä¸º**æ—¶é—´**ï¼›')
        st.write('3. è¯·æŒ‰ä¾§è¾¹æ å¯¼èˆªé€æ­¥å®Œæˆ**æ•°æ®ä¸Šä¼ **ã€**æ•°æ®å¤„ç†**ã€**ç‰¹å¾é€‰æ‹©**å’Œ**æ—¶é—´åºåˆ—åˆ’åˆ†**ï¼Œå†å¼€å§‹æ¨¡å‹è®­ç»ƒï¼›')
        st.write('4. åœ¨æœªå®Œæˆæ¨¡å‹è®­ç»ƒå‰ï¼Œæ— æ³•åœ¨**æ¨¡å‹åº”ç”¨**ä¸­è¿›è¡Œé¢„æµ‹ã€‚')
# ç¬¬äºŒéƒ¨åˆ†çš„ç¬¬ä¸€é¡µï¼šæ•°æ®ä¸Šä¼ å¹¶æ˜¾ç¤º
def page_21():
    # ä¸Šä¼ è®­ç»ƒæ•°æ®
    with st.container(border=True):
        # è®¾ç½®å­æ ‡é¢˜
        st.subheader('ä¸Šä¼ è®­ç»ƒæ•°æ®')
        # è®¾ç½®ä¸Šä¼ æ¨¡å—
        uploaded_file = st.file_uploader("åœ¨ä¸Šä¼ æ•°æ®å‰è¯·é˜…è¯»**æ³¨æ„äº‹é¡¹**ï¼Œå¹¶æ ¹æ®è¦æ±‚ä¸Šä¼ ã€‚")
    # æ˜¾ç¤ºä¸Šä¼ çš„æ•°æ®
    with st.container(border=True):
        # è®¾ç½®å­æ ‡é¢˜
        st.subheader('åŠ è½½æ•°æ®')
        # æ£€æŸ¥æ˜¯å¦ä¸Šä¼ äº†æ•°æ®
        if uploaded_file is not None:
            with st.spinner('è¯·è€å¿ƒç­‰å¾…...'):
                # è½¬æ¢ä¸ºdataframeæ ¼å¼å‡†å¤‡å‚¨å­˜ä¸ºexcelä»¥ä¾›åç»­è°ƒç”¨
                dataframe = pd.read_excel(uploaded_file)
                # è½¬æ¢æ—¶é—´æ ¼å¼
                dataframe['æ—¶é—´'] = pd.to_datetime(dataframe['æ—¶é—´'],
                                                 format='%Y-%m-%d %H:%M:%S')
                # å°†æ—¶é—´ä¿¡æ¯è½¬æ¢ä¸ºç´¢å¼•
                dataframe.index = dataframe['æ—¶é—´']
                # åˆ é™¤å¤šä½™çš„æ—¶é—´åˆ—
                dataframe.drop(columns=['æ—¶é—´'], axis=1, inplace=True)
                # æ£€æŸ¥æ˜¯å¦å­˜åœ¨ç¼“å­˜æ–‡ä»¶å¤¹ï¼Œè‹¥æ²¡æœ‰åˆ™åˆ›å»ºç¼“å­˜æ–‡ä»¶å¤¹
                if not os.path.exists('Cache'):
                    os.mkdir('Cache')
                if not os.path.exists('Cache/model'):
                    os.mkdir('Cache/model')
                if not os.path.exists('Cache/history'):
                    os.mkdir('Cache/history')
                # å°†ä¸Šä¼ çš„æ•°æ®ä¿å­˜äºç¼“å­˜ç›®å½•
                dataframe.to_excel('Cache/raw data.xlsx', sheet_name='raw')
                # æˆåŠŸä¸Šä¼ æç¤º
                st.success('ä¸Šä¼ æˆåŠŸï¼', icon="âœ…")
                # æ˜¾ç¤ºå·²ç»ä¸Šä¼ çš„æ•°æ®
                st.caption('ä½ ä¸Šä¼ çš„æ•°æ®å¦‚ä¸‹æ‰€ç¤ºï¼š')
                st.dataframe(dataframe, use_container_width=True)
        # è‹¥æœªæ£€æµ‹åˆ°ä¸Šä¼ çš„æ•°æ®åˆ™æç¤ºä¸Šä¼ æ•°æ®
        else:
            st.caption('ä½ ä¸Šä¼ çš„æ•°æ®å¦‚ä¸‹æ‰€ç¤ºï¼š')
            st.info('è¯·ä¸Šä¼ è®­ç»ƒæ•°æ®ï¼', icon="â„¹ï¸")
# ç¬¬äºŒéƒ¨åˆ†çš„ç¬¬äºŒé¡µï¼šç¼ºå¤±å€¼å¡«å……ã€æ•°æ®æ ‡å‡†åŒ–
def page_22():
    with st.container(border=True):
        # è®¾ç½®å­æ ‡é¢˜
        st.subheader('å¡«å……ç¼ºå¤±å€¼')
        # æ£€æŸ¥æ˜¯å¦ä¸Šä¼ äº†æ•°æ®ï¼Œè‹¥æ²¡æœ‰åˆ™æé†’
        with st.spinner('æ£€æµ‹æ•°æ®ä¸­ï¼Œè¯·ç¨å...'):
            if check_sheet_exists(file_path='Cache/raw data.xlsx',
                                  sheet_name='raw'):
                # ä»ç¼“å­˜ç›®å½•ä¸­è¯»å–æ•°æ®å¹¶è½¬æ¢æ ¼å¼ä»¥ä¾¿äºæ˜¾ç¤º
                data = pd.read_excel('Cache/raw data.xlsx', sheet_name='raw')
                data['æ—¶é—´'] = pd.to_datetime(data['æ—¶é—´'],
                                            format='%Y-%m-%d %H:%M:%S')
                date_index = data['æ—¶é—´']
                data.index = date_index
                data.drop(columns=['æ—¶é—´'], axis=1, inplace=True)
                # æç¤ºæˆåŠŸæ£€æµ‹
                st.success("å·²æ£€æµ‹åˆ°ä¸Šä¼ æ•°æ®ï¼", icon="âœ…")
                # å¸ƒå±€ï¼Œå°†è¯¢é—®ç¼ºå¤±å€¼æ˜¯å¦å­˜åœ¨å’Œé€‰æ‹©å¡«å……æ–¹æ³•åˆ†æˆä¸¤åˆ—
                col_22_1, col_22_2 = st.columns(2)
                # è¯¢é—®ç”¨æˆ·æ˜¯å¦åŒ…å«ç¼ºå¤±å€¼
                with col_22_1:
                    missing = st.radio("æ˜¯å¦åŒ…å«ç¼ºå¤±å€¼ï¼Ÿ", options=["æ˜¯", "å¦"],
                                       index=None)
                # å¦‚æœç”¨æˆ·ç¡®å®šç¼ºå¤±å€¼å­˜åœ¨ï¼Œåˆ™è¦æ±‚ç”¨æˆ·é€‰æ‹©å¡«å……æ–¹æ³•ï¼Œå¦åˆ™ç¦ç”¨è¯¥é€‰é¡¹
                with col_22_2:
                    if missing == "æ˜¯":
                        missing_option = st.selectbox("è¯·é€‰æ‹©ç¼ºå¤±å€¼å¡«å……æ–¹æ³•ï¼š",
                                                      ("KNNå¡«å……", "ç§»åŠ¨å¹³å‡æ»¤æ³¢"),
                                                      index=None,
                                                      placeholder="å•å‡»æ­¤å¤„ä»¥é€‰æ‹©æ–¹æ³•")
                    else:
                        missing_option = st.selectbox("è¯·é€‰æ‹©ç¼ºå¤±å€¼å¡«å……æ–¹æ³•ï¼š",
                                                      ("KNNå¡«å……", "ç§»åŠ¨å¹³å‡æ»¤æ³¢"),
                                                      index=None,
                                                      placeholder="å•å‡»æ­¤å¤„ä»¥é€‰æ‹©æ–¹æ³•",
                                                      disabled=True)
                # å¦‚æœåŒ…å«ç¼ºå¤±å€¼ï¼Œåˆ™æ ¹æ®é€‰æ‹©çš„å¡«å……æ–¹æ³•å¡«å……ç¼ºå¤±å€¼
                if missing == "æ˜¯":
                    # ä½¿ç”¨ç§»åŠ¨å¹³å‡æ»¤æ³¢å¡«å……ç¼ºå¤±å€¼
                    if missing_option == "ç§»åŠ¨å¹³å‡æ»¤æ³¢":
                        # è®¾ç½®æäº¤è¡¨å•å¹¶è¦æ±‚ç”¨æˆ·è¾“å…¥æ—¶é—´çª—å£å€¼
                        with st.form('MAF_form'):
                            window_size = st.number_input("è¯·è¾“å…¥æ—¶é—´çª—å£å€¼ï¼š",
                                                          value=1)
                            submitted = st.form_submit_button('æäº¤')
                        # å¦‚æœç”¨æˆ·æäº¤æ—¶é—´çª—å£å€¼ï¼Œåˆ™åˆ©ç”¨ç§»åŠ¨å¹³å‡æ»¤æ³¢æ–¹æ³•è¿›è¡Œå¡«å……
                        if submitted:
                            # çº¿æ€§å¡«å……ç¼ºå¤±å€¼
                            def fill_missing_values(data):
                                filled_data = np.copy(data).astype(float)
                                missing_indices = np.isnan(filled_data)
                                filled_data[missing_indices] = np.interp(np.flatnonzero(missing_indices),
                                                                         np.flatnonzero(~missing_indices),
                                                                         filled_data[~missing_indices])
                                return filled_data
                            # ç§»åŠ¨å¹³å‡æ»¤æ³¢ï¼Œå¢å¼ºæ—¶åºç‰¹æ€§
                            def moving_average_smoothing(data, window_size):
                                smoothed_data = np.convolve(data,
                                                            np.ones(window_size)/window_size,
                                                            mode='same')
                                return smoothed_data
                            # è½¬æ¢ä¸ºNumPyæ•°ç»„ä»¥ä¾¿åç»­å¡«å……
                            numpy_data = data.to_numpy()
                            # æŒ‰åˆ—è¿›è¡Œçº¿æ€§å¡«å……ï¼Œå¹¶åœ¨å¡«å……ç»“æŸåè¿›è¡Œç§»åŠ¨å¹³å‡æ»¤æ³¢ä»¥å¢å¼ºæ—¶åºç‰¹æ€§
                            fill_data = []
                            for i in range(numpy_data.shape[1]):
                                x = fill_missing_values(numpy_data[:, i])
                                x = moving_average_smoothing(x, window_size)
                                fill_data.append(x)
                            # å°†numpyæ•°ç»„è½¬æ¢å›Dataframe
                            fill_data = pd.DataFrame(fill_data)
                            # å¯¹Dataframeè¿›è¡Œè½¬ç½®ä»¥æ­£ç¡®æ˜¾ç¤ºæ•°æ®
                            fill_data = fill_data.T
                            # å°†ç´¢å¼•è½¬æ¢ä¸ºæ—¶é—´ä¿¡æ¯
                            fill_data.index = date_index
                            # å°†åˆ—åæ”¹ä¸ºæ­£ç¡®çš„åˆ—åï¼Œä¸dataç›¸åŒ
                            fill_data.columns = data.columns
                            # å°†å¡«å……å¥½çš„æ•°æ®ä¿å­˜äºç¼“å­˜ç›®å½•
                            fill_data.to_excel('Cache/imputed data.xlsx',
                                               sheet_name='filled')
                        # åˆ¤æ–­ç¼“å­˜ç›®å½•ä¸­æ˜¯å¦å­˜åœ¨å¡«å……æ•°æ®ï¼Œè‹¥æœ‰åˆ™è¯»å–å¹¶æ˜¾ç¤º
                        if check_sheet_exists(file_path='Cache/imputed data.xlsx',
                                              sheet_name='filled'):
                            impute_data = pd.read_excel('Cache/imputed data.xlsx',
                                                        sheet_name='filled')
                            impute_data['æ—¶é—´'] = pd.to_datetime(impute_data['æ—¶é—´'],
                                                               format='%Y-%m-%d %H:%M:%S')
                            impute_data_index = impute_data['æ—¶é—´']
                            impute_data.index = impute_data_index
                            impute_data.drop(columns=['æ—¶é—´'], axis=1,
                                             inplace=True)
                            with st.expander('æ‚¨çš„æ•°æ®å¦‚ä¸‹æ‰€ç¤ºï¼š'):
                                st.dataframe(impute_data,
                                             use_container_width=True)
                        # æç¤ºç”¨æˆ·å®Œæˆå¡«å……
                        else:
                            with st.expander('æ‚¨çš„æ•°æ®å¦‚ä¸‹æ‰€ç¤ºï¼š', expanded=True):
                                st.info('è¯·æ‚¨å®Œæˆç¼ºå¤±å€¼çš„å¡«å……ï¼', icon="â„¹ï¸")
                    elif missing_option == "KNNå¡«å……":
                        # è®¾ç½®æäº¤è¡¨å•å¹¶è¦æ±‚ç”¨æˆ·æŒ‡å®šKå€¼
                        with st.form('KNN_form'):
                            n_neighbors = st.number_input("è¯·è¾“å…¥Kå€¼ï¼š", value=1,
                                                          min_value=1,
                                                          max_value=10)
                            submitted = st.form_submit_button('æäº¤')
                        # å¦‚æœç”¨æˆ·æäº¤Kå€¼ï¼Œåˆ™åˆ©ç”¨KNNæ–¹æ³•è¿›è¡Œå¡«å……
                        if submitted:
                            # KNNå¡«å……
                            imputer = KNNImputer(n_neighbors=n_neighbors)
                            impute_data = imputer.fit_transform(data)
                            # å°†æ•°æ®è½¬æ¢å›Dataframe
                            impute_data = pd.DataFrame(impute_data)
                            # å°†ç´¢å¼•è½¬æ¢ä¸ºæ—¶é—´ä¿¡æ¯
                            impute_data.index = date_index
                            # å°†åˆ—åæ”¹ä¸ºæ­£ç¡®çš„åˆ—åï¼Œä¸dataç›¸åŒ
                            impute_data.columns = data.columns
                            # å°†å¡«å……å¥½çš„æ•°æ®ä¿å­˜äºç¼“å­˜ç›®å½•
                            impute_data.to_excel('Cache/imputed data.xlsx',
                                                 sheet_name='filled')
                        # åˆ¤æ–­ç¼“å­˜ç›®å½•ä¸­æ˜¯å¦å­˜åœ¨å¡«å……æ•°æ®ï¼Œè‹¥æœ‰åˆ™è¯»å–å¹¶æ˜¾ç¤º
                        if check_sheet_exists(file_path='Cache/imputed data.xlsx',
                                              sheet_name='filled'):
                            impute_data = pd.read_excel('Cache/imputed data.xlsx',
                                                        sheet_name='filled')
                            impute_data['æ—¶é—´'] = pd.to_datetime(impute_data['æ—¶é—´'],
                                                               format='%Y-%m-%d %H:%M:%S')
                            impute_data_index = impute_data['æ—¶é—´']
                            impute_data.index = impute_data_index
                            impute_data.drop(columns=['æ—¶é—´'], axis=1,
                                             inplace=True)
                            with st.expander('æ‚¨çš„æ•°æ®å¦‚ä¸‹æ‰€ç¤ºï¼š'):
                                st.dataframe(impute_data,
                                             use_container_width=True)
                        # æç¤ºç”¨æˆ·å®Œæˆå¡«å……
                        else:
                            with st.expander('æ‚¨çš„æ•°æ®å¦‚ä¸‹æ‰€ç¤ºï¼š', expanded=True):
                                st.info('è¯·æ‚¨å®Œæˆç¼ºå¤±å€¼çš„å¡«å……ï¼', icon="â„¹ï¸")
                    # æç¤ºç”¨æˆ·åšå‡ºé€‰æ‹©
                    else:
                        with st.expander('æ‚¨çš„æ•°æ®å¦‚ä¸‹æ‰€ç¤ºï¼š', expanded=True):
                            st.info('è¯·é€‰æ‹©æ˜¯å¦åŒ…å«ç¼ºå¤±å€¼å¹¶é€‰æ‹©å¡«å……æ–¹æ³•ï¼', icon="â„¹ï¸")
                # å¦‚æœç”¨æˆ·é€‰æ‹©æ²¡æœ‰ç¼ºå¤±å€¼ï¼Œåˆ™ç›´æ¥æ˜¾ç¤ºåŸå§‹æ•°æ®
                elif missing == "å¦":
                    # å°†æ•°æ®ä¿å­˜äºç¼“å­˜ç›®å½•
                    data.to_excel('Cache/imputed data.xlsx',
                                  sheet_name='filled')
                    if check_sheet_exists(file_path='Cache/imputed data.xlsx',
                                  sheet_name='filled'):
                        # ä»ç¼“å­˜ç›®å½•ä¸­è¯»å–æ•°æ®å¹¶è½¬æ¢æ ¼å¼ä»¥ä¾¿äºæ˜¾ç¤º
                        impute_data = pd.read_excel('Cache/imputed data.xlsx',
                                                    sheet_name='filled')
                        impute_data['æ—¶é—´'] = pd.to_datetime(impute_data['æ—¶é—´'],
                                                           format='%Y-%m-%d %H:%M:%S')
                        impute_data_index = impute_data['æ—¶é—´']
                        impute_data.index = impute_data_index
                        impute_data.drop(columns=['æ—¶é—´'], axis=1, inplace=True)
                        # é€‰æ‹©æ˜¯å¦æ˜¾ç¤ºæ•°æ®
                        with st.expander('æ‚¨çš„æ•°æ®å¦‚ä¸‹æ‰€ç¤ºï¼š'):
                            st.dataframe(impute_data, use_container_width=True)
                    else:
                        # é€‰æ‹©æ˜¯å¦æ˜¾ç¤ºå¡«å……åçš„æ•°æ®
                        with st.expander('æ‚¨çš„æ•°æ®å¦‚ä¸‹æ‰€ç¤ºï¼š'):
                            st.info('è¯·é€‰æ‹©æ˜¯å¦åŒ…å«ç¼ºå¤±å€¼å¹¶é€‰æ‹©å¡«å……æ–¹æ³•ï¼', icon="â„¹ï¸")
                # è‹¥æœªæ£€æµ‹åˆ°å¡«å……åçš„æ•°æ®åˆ™æç¤º
                else:
                    with st.expander('æ‚¨çš„æ•°æ®å¦‚ä¸‹æ‰€ç¤ºï¼š', expanded=True):
                        st.info('è¯·é€‰æ‹©æ˜¯å¦åŒ…å«ç¼ºå¤±å€¼å¹¶é€‰æ‹©å¡«å……æ–¹æ³•ï¼', icon="â„¹ï¸")
            # è‹¥æœªæ£€æµ‹åˆ°ä¸Šä¼ æ•°æ®ï¼Œåˆ™ç¦ç”¨æ‰€æœ‰é€‰é¡¹å¹¶æç¤ºä¸Šä¼ 
            else:
                col_22_1, col_22_2 = st.columns(2)
                with col_22_1:
                    missing = st.radio("æ˜¯å¦åŒ…å«ç¼ºå¤±å€¼ï¼Ÿ", options=["æ˜¯", "å¦"],
                                       index=None, disabled=True)
                with col_22_2:
                    missing_option = st.selectbox("è¯·é€‰æ‹©ç¼ºå¤±å€¼å¡«å……æ–¹æ³•ï¼š",
                                                  ("KNNå¡«å……", "ç§»åŠ¨å¹³å‡æ»¤æ³¢"),
                                                  index=None, disabled=True,
                                                  placeholder="å•å‡»æ­¤å¤„ä»¥é€‰æ‹©æ–¹æ³•")
                with st.expander('æ‚¨çš„æ•°æ®å¦‚ä¸‹æ‰€ç¤ºï¼š', expanded=True):
                    st.info('è¯·ä¸Šä¼ è®­ç»ƒæ•°æ®ï¼', icon="â„¹ï¸")
    with st.container(border=True):
        # è®¾ç½®å­æ ‡é¢˜
        st.subheader('æ ‡å‡†åŒ–æ•°æ®')
        # æ£€æŸ¥æ˜¯å¦å¡«å……äº†ç¼ºå¤±å€¼ï¼Œè‹¥æ²¡æœ‰åˆ™æé†’
        with st.spinner('æ£€æµ‹æ•°æ®ä¸­ï¼Œè¯·ç¨å...'):
            if check_sheet_exists(file_path='Cache/imputed data.xlsx',
                                  sheet_name='filled'):
                # ä»ç¼“å­˜ç›®å½•ä¸­è¯»å–æ•°æ®å¹¶è½¬æ¢æ ¼å¼ä»¥ä¾¿äºæ“ä½œ
                data = pd.read_excel('Cache/imputed data.xlsx',
                                     sheet_name='filled')
                data['æ—¶é—´'] = pd.to_datetime(data['æ—¶é—´'],
                                            format='%Y-%m-%d %H:%M:%S')
                data_index = data['æ—¶é—´']
                data.index = data_index
                data.drop(columns=['æ—¶é—´'], axis=1, inplace=True)
                # æç¤ºæˆåŠŸæ£€æµ‹
                st.success("å·²æ£€æµ‹åˆ°å¡«å……æ•°æ®ï¼", icon="âœ…")
                # è¦æ±‚ç”¨æˆ·é€‰æ‹©æ ‡å‡†åŒ–æ–¹æ³•
                norm_option = st.selectbox("è¯·é€‰æ‹©æ•°æ®æ ‡å‡†åŒ–æ–¹æ³•ï¼š",
                                           ("æœ€å¤§æœ€å°å€¼å½’ä¸€åŒ–", "Zå€¼è§„èŒƒåŒ–", "é²æ£’ç¼©æ”¾"),
                                           index=None,
                                           placeholder="å•å‡»æ­¤å¤„ä»¥é€‰æ‹©æ–¹æ³•")
                if norm_option == "æœ€å¤§æœ€å°å€¼å½’ä¸€åŒ–":
                    # æœ€å¤§æœ€å°å€¼å½’ä¸€åŒ–
                    scaler = preprocessing.MinMaxScaler()
                    # å‚¨å­˜æ•°æ®æ ‡å‡†åŒ–æ–¹æ³•
                    with open('Cache/scaler.pkl', 'wb') as f:
                        pickle.dump(scaler, f)
                    # è®¡ç®—æ ‡å‡†åŒ–æ•°æ®
                    scaled_data = scaler.fit_transform(data)
                    # å°†æ•°æ®è½¬æ¢å›Dataframe
                    scaled_data = pd.DataFrame(scaled_data)
                    # å°†ç´¢å¼•è½¬æ¢ä¸ºæ—¶é—´ä¿¡æ¯
                    scaled_data.index = data_index
                    # å°†åˆ—åæ”¹ä¸ºæ­£ç¡®çš„åˆ—åï¼Œä¸dataç›¸åŒ
                    scaled_data.columns = data.columns
                    # å°†å¡«å……å¥½çš„æ•°æ®ä¿å­˜äºç¼“å­˜ç›®å½•
                    scaled_data.to_excel('Cache/normalized data.xlsx',
                                         sheet_name='scaled')
                    # é€‰æ‹©æ˜¯å¦æ˜¾ç¤ºå¡«å……å¥½çš„æ•°æ®
                    with st.expander('æ‚¨çš„æ ‡å‡†åŒ–æ•°æ®å¦‚ä¸‹æ‰€ç¤ºï¼š'):
                        st.dataframe(scaled_data, use_container_width=True)
                elif norm_option == "Zå€¼è§„èŒƒåŒ–":
                    # Zå€¼è§„èŒƒåŒ–ï¼Œå…¶ä»–åŒä¸Š
                    scaler = preprocessing.StandardScaler()
                    with open('Cache/scaler.pkl', 'wb') as f:
                        pickle.dump(scaler, f)
                    scaled_data = scaler.fit_transform(data)
                    scaled_data = pd.DataFrame(scaled_data)
                    scaled_data.index = date_index
                    scaled_data.columns = data.columns
                    scaled_data.to_excel('Cache/normalized data.xlsx',
                                         sheet_name='scaled')
                    with st.expander('æ‚¨çš„æ ‡å‡†åŒ–æ•°æ®å¦‚ä¸‹æ‰€ç¤ºï¼š'):
                        st.dataframe(scaled_data, use_container_width=True)
                elif norm_option == "é²æ£’ç¼©æ”¾":
                    # é²æ£’ç¼©æ”¾ï¼Œå…¶ä»–åŒä¸Š
                    scaler = preprocessing.RobustScaler()
                    with open('Cache/scaler.pkl', 'wb') as f:
                        pickle.dump(scaler, f)
                    scaled_data = scaler.fit_transform(data)
                    scaled_data = pd.DataFrame(scaled_data)
                    scaled_data.index = data_index
                    scaled_data.columns = data.columns
                    scaled_data.to_excel('Cache/normalized data.xlsx',
                                         sheet_name='scaled')
                    with st.expander('æ‚¨çš„æ ‡å‡†åŒ–æ•°æ®å¦‚ä¸‹æ‰€ç¤ºï¼š'):
                        st.dataframe(scaled_data, use_container_width=True)
                else:
                    with st.expander('æ‚¨çš„æ ‡å‡†åŒ–æ•°æ®å¦‚ä¸‹æ‰€ç¤ºï¼š', expanded=True):
                        st.info('è¯·é€‰æ‹©ä¸€ç§æ•°æ®æ ‡å‡†åŒ–æ–¹æ³•ï¼', icon="â„¹ï¸")
            # è‹¥æœªæ£€æµ‹åˆ°å¡«å……æ•°æ®ï¼Œåˆ™ç¦ç”¨æ‰€æœ‰é€‰é¡¹å¹¶æç¤ºä¸Šä¼ 
            else:
                norm_option = st.selectbox("è¯·é€‰æ‹©æ•°æ®æ ‡å‡†åŒ–æ–¹æ³•ï¼š",
                                           ("æœ€å¤§æœ€å°å€¼å½’ä¸€åŒ–", "Zå€¼è§„èŒƒåŒ–", "é²æ£’ç¼©æ”¾"),
                                           index=None, disabled=True,
                                           placeholder="å•å‡»æ­¤å¤„ä»¥é€‰æ‹©æ–¹æ³•")
                with st.expander('æ‚¨çš„æ ‡å‡†åŒ–æ•°æ®å¦‚ä¸‹æ‰€ç¤ºï¼š', expanded=True):
                    st.info('è¯·ä¸Šä¼ å¹¶å¡«å……è®­ç»ƒæ•°æ®ï¼', icon="â„¹ï¸")
# ç¬¬äºŒéƒ¨åˆ†çš„ç¬¬ä¸‰é¡µï¼šé€‰æ‹©è¾“å…¥å’Œè¾“å‡ºå˜é‡
def page_23():
    with st.container(border=True):
        # è®¾ç½®å­æ ‡é¢˜
        st.subheader('é€‰æ‹©å˜é‡')
        # æ£€æŸ¥æ˜¯å¦æ ‡å‡†åŒ–äº†æ•°æ®å€¼ï¼Œè‹¥æ²¡æœ‰åˆ™æé†’
        with st.spinner('æ£€æµ‹æ•°æ®ä¸­ï¼Œè¯·ç¨å...'):
            if check_sheet_exists(file_path='Cache/normalized data.xlsx',
                                  sheet_name='scaled'):
                # ä»ç¼“å­˜ç›®å½•ä¸­è¯»å–æ•°æ®å¹¶è½¬æ¢æ ¼å¼ä»¥ä¾¿äºæ“ä½œ
                data = pd.read_excel('Cache/normalized data.xlsx',
                                     sheet_name='scaled')
                data['æ—¶é—´'] = pd.to_datetime(data['æ—¶é—´'],
                                            format='%Y-%m-%d %H:%M:%S')
                data_index = data['æ—¶é—´']
                data.index = data_index
                data.drop(columns=['æ—¶é—´'], axis=1, inplace=True)
                data_colums = data.columns
                # æç¤ºæˆåŠŸæ£€æµ‹
                st.success("å·²æ£€æµ‹åˆ°æ ‡å‡†åŒ–æ•°æ®ï¼", icon="âœ…")
                # è®¾ç½®æäº¤è¡¨å•
                with st.form('feature_form'):
                    # è¦æ±‚ç”¨æˆ·é€‰æ‹©è¾“å…¥å˜é‡
                    X_options = st.multiselect("**è¾“å…¥å˜é‡**", data_colums,
                                               placeholder='è¯·é€‰æ‹©æ¨¡å‹çš„è¾“å…¥å˜é‡')
                    # è¦æ±‚ç”¨æˆ·é€‰æ‹©è¾“å‡ºå˜é‡
                    y_options = st.multiselect("**è¾“å‡ºå˜é‡**", data_colums,
                                               placeholder='è¯·é€‰æ‹©æ¨¡å‹çš„è¾“å‡ºå˜é‡')
                    submitted = st.form_submit_button('æäº¤')
            # è‹¥æœªæ£€æµ‹åˆ°æ ‡å‡†åŒ–æ•°æ®ï¼Œåˆ™ç¦ç”¨æ‰€æœ‰é€‰é¡¹å¹¶æç¤ºå¤„ç†
            else:
                st.info('è¯·å®Œæˆæ•°æ®å¤„ç†ï¼', icon="â„¹ï¸")
                with st.form('feature_form'):
                    X_options = st.multiselect("**è¾“å…¥å˜é‡**", ["æ²¡", "ç”¨"],
                                               placeholder='è¯·é€‰æ‹©æ¨¡å‹çš„è¾“å‡ºå˜é‡',
                                               disabled=True)
                    y_options = st.multiselect("**è¾“å‡ºå˜é‡**", ["æ²¡", "ç”¨"],
                                               placeholder='è¯·é€‰æ‹©æ¨¡å‹çš„è¾“å‡ºå˜é‡',
                                               disabled=True)
                    submitted = st.form_submit_button('æäº¤', disabled=True)
    with st.container(border=True):
        # è®¾ç½®å­æ ‡é¢˜
        st.subheader('æ•°æ®é›†')
        # æäº¤å˜é‡è¡¨å•åï¼Œåˆ¤æ–­ç”¨æˆ·æ˜¯å¦æäº¤äº†ç©ºçš„è¡¨å•
        if submitted:
            # åˆ¤æ–­X_optionsæˆ–y_optionsæ˜¯å¦ä¸ºç©ºï¼Œå¦‚æœä¸ºç©ºåˆ™ç»™å‡ºæç¤º
            if not X_options or not y_options:
                st.error("è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªè¾“å…¥æˆ–è¾“å‡ºå˜é‡ï¼", icon="ğŸš¨")
            # å¦‚æœä¸ä¸ºç©ºï¼Œåˆ™å°†å¯¹åº”çš„æ•°æ®å‚¨å­˜åœ¨ç¼“å­˜ç›®å½•å¹¶æ˜¾ç¤ºåœ¨å‰ç«¯
            else:
                with st.spinner('åˆ’åˆ†å˜é‡ä¸­ï¼Œè¯·ç¨å...'):
                    X_new = data[X_options]
                    y_new = data[y_options]
                    # å¸ƒå±€ï¼Œå°†è¾“å…¥å’Œè¾“å‡ºæ•°æ®åˆ†æˆå·¦å³ä¸¤éƒ¨åˆ†æ˜¾ç¤º
                    col_X, col_y = st.columns(2)
                    # å·¦éƒ¨åˆ†æ˜¾ç¤ºè¾“å…¥å˜é‡çš„æ•°æ®
                    with col_X:
                        # å°†è¾“å…¥å˜é‡å‚¨å­˜åœ¨ç¼“å­˜ç›®å½•ä¸­
                        X_new.to_excel('Cache/X data.xlsx', sheet_name='X')
                        # æ˜¾ç¤ºè¾“å…¥å˜é‡
                        st.caption('æ‚¨çš„è¾“å…¥å˜é‡å¦‚ä¸‹æ‰€ç¤ºï¼š')
                        st.write(X_new)
                    # å³éƒ¨åˆ†æ˜¾ç¤ºè¾“å‡ºå˜é‡çš„æ•°æ®
                    with col_y:
                        # å°†è¾“å‡ºå˜é‡å‚¨å­˜åœ¨ç¼“å­˜ç›®å½•ä¸­
                        y_new.to_excel('Cache/y data.xlsx', sheet_name='y')
                        # æ˜¾ç¤ºè¾“å‡ºå˜é‡
                        st.caption('æ‚¨çš„è¾“å‡ºå˜é‡å¦‚ä¸‹æ‰€ç¤ºï¼š')
                        st.write(y_new)
        # å¦‚æœç”¨æˆ·æœªæäº¤è¡¨å•ï¼Œåˆ™æç¤º
        else:
            col_X, col_y = st.columns(2)
            with col_X:
                st.caption('æ‚¨çš„è¾“å…¥å˜é‡å¦‚ä¸‹æ‰€ç¤ºï¼š')
                st.info('è¯·é€‰æ‹©æœŸæœ›çš„è¾“å…¥å˜é‡ï¼Œå¹¶ç‚¹å‡»**æäº¤**ï¼', icon="â„¹ï¸")
            # å³éƒ¨åˆ†æ˜¾ç¤ºè¾“å‡ºå˜é‡çš„æ•°æ®
            with col_y:
                st.caption('æ‚¨çš„è¾“å‡ºå˜é‡å¦‚ä¸‹æ‰€ç¤ºï¼š')
                st.info('è¯·é€‰æ‹©æœŸæœ›çš„è¾“å‡ºå˜é‡ï¼Œå¹¶ç‚¹å‡»**æäº¤**ï¼', icon="â„¹ï¸")
# ç¬¬ä¸‰éƒ¨åˆ†çš„ç¬¬ä¸€é¡µï¼šåˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
def page_31():
    with st.container(border=True):
        # è®¾ç½®å­æ ‡é¢˜
        st.subheader('é€‰æ‹©åˆ’åˆ†æ¯”ä¾‹')
        # æ£€æŸ¥æ˜¯å¦æŒ‡å®šäº†è¾“å…¥å˜é‡ï¼Œè‹¥æ²¡æœ‰åˆ™æé†’
        with st.spinner('æ£€æµ‹æ•°æ®ä¸­ï¼Œè¯·ç¨å...'):
            # æ£€æŸ¥è¾“å…¥å˜é‡æ•°æ®å’Œè¾“å‡ºå˜é‡æ•°æ®æ˜¯å¦å­˜åœ¨
            x_data_exists = check_sheet_exists(file_path='Cache/X data.xlsx',
                                               sheet_name='X')
            y_data_exists = check_sheet_exists(file_path='Cache/y data.xlsx',
                                               sheet_name='y')
            if x_data_exists and y_data_exists:
                # å¸ƒå±€ï¼Œå°†æ•°æ®ç›‘æµ‹æç¤ºåˆ†æˆå·¦å³ä¸¤éƒ¨åˆ†æ˜¾ç¤º
                col_31_X, col_31_y = st.columns(2)
                # å·¦éƒ¨åˆ†æç¤ºè¾“å…¥å˜é‡æ£€æµ‹æˆåŠŸ
                with col_31_X:
                    # ä»ç¼“å­˜ç›®å½•ä¸­è¯»å–æ•°æ®å¹¶è½¬æ¢æ ¼å¼ä»¥ä¾¿äºæ“ä½œ
                    X = pd.read_excel('Cache/X data.xlsx', sheet_name='X')
                    X['æ—¶é—´'] = pd.to_datetime(X['æ—¶é—´'],
                                             format='%Y-%m-%d %H:%M:%S')
                    X_index = X['æ—¶é—´']
                    X.index = X_index
                    X.drop(columns=['æ—¶é—´'], axis=1, inplace=True)
                    X_colums = X.columns
                    # æç¤ºæˆåŠŸæ£€æµ‹
                    st.success("å·²æ£€æµ‹åˆ°è¾“å…¥å˜é‡æ•°æ®ï¼", icon="âœ…")
                # å³éƒ¨åˆ†æç¤ºè¾“å‡ºå˜é‡æ£€æµ‹æˆåŠŸ
                with col_31_y:
                    # ä»ç¼“å­˜ç›®å½•ä¸­è¯»å–æ•°æ®å¹¶è½¬æ¢æ ¼å¼ä»¥ä¾¿äºæ“ä½œ
                    y = pd.read_excel('Cache/y data.xlsx', sheet_name='y')
                    y['æ—¶é—´'] = pd.to_datetime(y['æ—¶é—´'],
                                             format='%Y-%m-%d %H:%M:%S')
                    y_index = y['æ—¶é—´']
                    y.index = y_index
                    y.drop(columns=['æ—¶é—´'], axis=1, inplace=True)
                    y_colums = y.columns
                    # æç¤ºæˆåŠŸæ£€æµ‹
                    st.success("å·²æ£€æµ‹åˆ°è¾“å‡ºå˜é‡æ•°æ®ï¼", icon="âœ…")
                # è®¾ç½®æäº¤è¡¨å•å¹¶è¦æ±‚ç”¨æˆ·é€‰æ‹©æ•°æ®åˆ’åˆ†æ¯”ä¾‹
                with st.form('feature_form'):
                    split_ratio = st.slider("è¯·é€‰æ‹©æ•°æ®åˆ’åˆ†æ¯”ä¾‹ï¼Œå³è®­ç»ƒé›†çš„å æ¯”ï¼ˆ%ï¼‰ï¼š",
                                            min_value=50, max_value=90,
                                            value=80)
                    submitted = st.form_submit_button('æäº¤')
            # è‹¥æœªæ£€æµ‹åˆ°è¾“å…¥å’Œè¾“å‡ºæ•°æ®ï¼Œåˆ™ç¦ç”¨æ‰€æœ‰é€‰é¡¹å¹¶æç¤º
            else:
                col_31_X, col_31_y = st.columns(2)
                with col_31_X:
                    if not x_data_exists:
                        st.info("è¯·é€‰æ‹©åˆé€‚çš„è¾“å…¥å˜é‡ï¼", icon="â„¹ï¸")
                with col_31_y:
                    if not y_data_exists:
                        st.info("è¯·é€‰æ‹©åˆé€‚çš„è¾“å‡ºå˜é‡ï¼", icon="â„¹ï¸")
                with st.form('feature_form'):
                    split_ratio = st.slider("è¯·é€‰æ‹©æ•°æ®åˆ’åˆ†æ¯”ä¾‹ï¼Œå³è®­ç»ƒé›†çš„å æ¯”ï¼ˆ%ï¼‰ï¼š",
                                            min_value=50, max_value=90,
                                            value=80, disabled= True)
                    submitted = st.form_submit_button('æäº¤', disabled= True)
                
    with st.container(border=True):
        # è®¾ç½®å­æ ‡é¢˜
        st.subheader('è®­ç»ƒâ€”æµ‹è¯•æ•°æ®é›†')
        # æäº¤è¡¨å•åï¼Œæ ¹æ®ç”¨æˆ·æä¾›çš„æ¯”ä¾‹åˆ’åˆ†æ•°æ®é›†
        if submitted:
            with st.spinner('åˆ’åˆ†æ•°æ®ä¸­ï¼Œè¯·ç¨å...'):
                # åˆå¹¶è¾“å…¥å’Œè¾“å‡ºæ•°æ®
                data = pd.concat([X, y], axis=1)
                data_colums = data.columns
                # å°†æ•°æ®åˆ’åˆ†ä¸ºè®­ç»ƒæ•°æ®å’Œæµ‹è¯•æ•°æ®
                train_size = int(split_ratio/100 * len(data))
                data_train = data[:train_size]
                data_test = data[train_size:]
                # ä»è®­ç»ƒæ•°æ®å’Œæµ‹è¯•æ•°æ®ä¸­æå–è¾“å…¥å’Œè¾“å‡ºå˜é‡
                y_train = data_train[y_colums]
                X_train = data_train[X_colums]
                y_test = data_test[y_colums]
                X_test = data_test[X_colums]
                # å°†æ‰€æœ‰æ•°æ®å‚¨å­˜åœ¨ç¼“å­˜ç›®å½•ä¸­ä»¥ä¾¿åç»­è°ƒç”¨
                y_train.to_excel('Cache/y train data.xlsx', sheet_name='y')
                X_train.to_excel('Cache/X train data.xlsx', sheet_name='X')
                y_test.to_excel('Cache/y test data.xlsx', sheet_name='y')
                X_test.to_excel('Cache/X test data.xlsx', sheet_name='X')
                # é€‰æ‹©æ˜¯å¦æ˜¾ç¤ºè®­ç»ƒæ•°æ®å’Œæµ‹è¯•æ•°æ®ä¸­çš„è¾“å…¥å’Œè¾“å‡ºå˜é‡
                with st.expander('æ‚¨çš„è®­ç»ƒæ•°æ®å¦‚ä¸‹æ‰€ç¤ºï¼š'):
                    # å¸ƒå±€ï¼Œå°†è®­ç»ƒæ•°æ®ä¸­çš„è¾“å…¥å’Œè¾“å‡ºå˜é‡åˆ†æˆå·¦å³ä¸¤éƒ¨åˆ†æ˜¾ç¤º
                    col_X_train, col_y_train = st.columns(2)
                    # å·¦éƒ¨åˆ†æ˜¾ç¤ºè®­ç»ƒæ•°æ®ä¸­çš„è¾“å…¥å˜é‡
                    with col_X_train:
                        st.caption('è¾“å…¥å˜é‡ï¼š')
                        st.write(X_train)
                    # å³éƒ¨åˆ†æ˜¾ç¤ºè®­ç»ƒæ•°æ®ä¸­çš„è¾“å‡ºå˜é‡
                    with col_y_train:
                       st.caption('è¾“å‡ºå˜é‡ï¼š')
                       st.write(y_train)
                # é€‰æ‹©æ˜¯å¦æ˜¾ç¤ºè®­ç»ƒæ•°æ®å’Œæµ‹è¯•æ•°æ®ä¸­çš„è¾“å…¥å’Œè¾“å‡ºå˜é‡
                with st.expander('æ‚¨çš„æµ‹è¯•æ•°æ®å¦‚ä¸‹æ‰€ç¤ºï¼š'):
                    # å¸ƒå±€ï¼Œå°†æµ‹è¯•æ•°æ®ä¸­çš„è¾“å…¥å’Œè¾“å‡ºå˜é‡åˆ†æˆå·¦å³ä¸¤éƒ¨åˆ†æ˜¾ç¤º
                    col_X_test, col_y_test = st.columns(2)
                    # å·¦éƒ¨åˆ†æ˜¾ç¤ºæµ‹è¯•æ•°æ®ä¸­çš„è¾“å…¥å˜é‡
                    with col_X_test:
                        st.caption('è¾“å…¥å˜é‡ï¼š')
                        st.write(X_test)
                    # å³éƒ¨åˆ†æ˜¾ç¤ºæµ‹è¯•æ•°æ®ä¸­çš„è¾“å‡ºå˜é‡
                    with col_y_test:
                        st.caption('è¾“å…¥å˜é‡ï¼š')
                        st.write(y_test)
        # å¦‚æœç”¨æˆ·æœªæäº¤è¡¨å•ï¼Œåˆ™æç¤º
        else:
            with st.expander('æ‚¨çš„è®­ç»ƒæ•°æ®å¦‚ä¸‹æ‰€ç¤ºï¼š', expanded=True):
                st.info('è¯·é€‰æ‹©æœŸæœ›çš„æ•°æ®åˆ’åˆ†æ¯”ä¾‹ï¼Œå¹¶ç‚¹å‡»**æäº¤**ï¼', icon="â„¹ï¸")
            with st.expander('æ‚¨çš„æµ‹è¯•æ•°æ®å¦‚ä¸‹æ‰€ç¤ºï¼š'):
                st.info('è¯·é€‰æ‹©æœŸæœ›çš„æ•°æ®åˆ’åˆ†æ¯”ä¾‹ï¼Œå¹¶ç‚¹å‡»**æäº¤**ï¼', icon="â„¹ï¸")
# ç¬¬ä¸‰éƒ¨åˆ†çš„ç¬¬äºŒé¡µï¼šLSTMæ¨¡å‹
def page_32():
    with st.container(border=True):
        # è®¾ç½®å­æ ‡é¢˜
        st.subheader('*é•¿çŸ­æœŸè®°å¿†ç¥ç»ç½‘ç»œï¼ˆLSTMï¼‰*')
        with st.spinner('æ£€æµ‹æ•°æ®ä¸­ï¼Œè¯·ç¨å...'):
            # æ£€æŸ¥æ•°æ®æ˜¯å¦å­˜åœ¨
            X_train_exists = check_sheet_exists(file_path='Cache/X train data.xlsx',
                                                sheet_name='X')
            y_train_exists = check_sheet_exists(file_path='Cache/y train data.xlsx',
                                                sheet_name='y')
            X_test_exists = check_sheet_exists(file_path='Cache/X test data.xlsx',
                                               sheet_name='X')
            y_test_exists = check_sheet_exists(file_path='Cache/y test data.xlsx',
                                               sheet_name='y')
            if X_train_exists and X_test_exists and y_train_exists and y_test_exists:
                # æç¤ºæˆåŠŸæ£€æµ‹
                st.success("å·²æ£€æµ‹åˆ°åˆ’åˆ†çš„è®­ç»ƒé›†å’Œæµ‹è¯•é›†ï¼è¯·æ‚¨æŒ‰ç…§æµç¨‹å®Œæˆè®­ç»ƒï¼", icon="âœ…")
                # è¦æ±‚ç”¨æˆ·é€‰æ‹©è¶…å‚æ•°è°ƒä¼˜æ–¹æ³•
                hp_option = st.selectbox("**è¯·é€‰æ‹©è¶…å‚æ•°è°ƒä¼˜æ–¹æ³•ï¼š**",
                                         ("ç½‘æ ¼æœç´¢", "éšæœºæœç´¢", "è´å¶æ–¯ä¼˜åŒ–",
                                          "Hyperband", "äººä¸ºæŒ‡å®š"), index=4)
                # å¦‚æœé€‰æ‹©äººä¸ºæŒ‡å®šï¼Œåˆ™æ¿€æ´»æ‰€æœ‰åŠŸèƒ½
                if hp_option == "äººä¸ºæŒ‡å®š":
                    # è®¾ç½®æäº¤è¡¨å•
                    with st.form('lstm_form'):
                        # è¦æ±‚ç”¨æˆ·é€‰æ‹©æ—¶é—´æ­¥é•¿
                        seq_length = st.number_input("**æ—¶é—´æ­¥é•¿ï¼š**", value=7,
                                                     min_value=1)
                        # è¦æ±‚ç”¨æˆ·é€‰æ‹©æ¿€æ´»å‡½æ•°
                        act_option = st.selectbox("**éšè—å±‚æ¿€æ´»å‡½æ•°ï¼š**",
                                                  ("relu", "tanh", "sigmoid",
                                                   "linear", "exponential"))
                        # è¦æ±‚ç”¨æˆ·æŒ‡å®šéšæœºå¤±æ´»
                        dropout = st.number_input("**éšæœºå¤±æ´»æ¯”ä¾‹ï¼š**", value=0.0,
                                                  min_value=0.0, max_value=0.8)
                        # è¦æ±‚ç”¨æˆ·ä¸ºæå‰ç»ˆæ­¢æ³•æŒ‡å®šéªŒè¯æ¯”ä¾‹
                        early = st.number_input("**æå‰ç»ˆæ­¢æ³•éªŒè¯æ¯”ä¾‹ï¼š**",
                                                value=0.2, min_value=0.1,
                                                max_value=0.5)
                        # è¦æ±‚ç”¨æˆ·é€‰æ‹©ä¼˜åŒ–å™¨
                        optimizer = st.selectbox("**ä¼˜åŒ–å™¨ï¼š**",
                                                 ("adam", "sgd", "rmsprop",
                                                  "adadelta"))
                        # è¦æ±‚ç”¨æˆ·æŒ‡å®šæ‰¹æ¬¡å¤§å°
                        batch = st.number_input("**æ‰¹æ¬¡å¤§å°ï¼š**",
                                                value=32, min_value=8)
                        # è¦æ±‚ç”¨æˆ·æŒ‡å®šæœ€å¤§è¿­ä»£æ¬¡æ•°
                        epoch = st.number_input("**æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼š**",
                                                value=1000, min_value=100)
                        # è‹¥è¶…å‚æ•°è°ƒä¼˜æ–¹æ³•é€‰æ‹©äººå·¥æŒ‡å®šåˆ™è¦æ±‚ç”¨æˆ·é€‰æ‹©GRUçš„èŠ‚ç‚¹æ•°å’Œå±‚æ•°
                        lstm_layers = st.number_input("**éšè—å±‚å±‚æ•°ï¼š**",
                                                      value=1, min_value=1)
                        lstm_units = st.number_input("**éšè—å±‚èŠ‚ç‚¹æ•°ï¼š**",
                                                     value=8, min_value=1)
                        # è®¾ç½®æäº¤æŒ‰é’®
                        submitted = st.form_submit_button('ç¡®å®šå¹¶è®­ç»ƒ')
                # å¦‚æœä½¿ç”¨æœç´¢æ–¹æ³•ï¼Œåˆ™ç¦ç”¨ä¸€éƒ¨åˆ†åŠŸèƒ½
                else:
                    # è®¾ç½®æäº¤è¡¨å•
                    with st.form('lstm_form'):
                        seq_length = st.number_input("**æ—¶é—´æ­¥é•¿ï¼š**", value=7,
                                                     min_value=1)
                        act_option = st.selectbox("**éšè—å±‚æ¿€æ´»å‡½æ•°ï¼š**",
                                                  ("relu", "tanh", "sigmoid",
                                                   "linear", "exponential"))
                        dropout = st.number_input("**éšæœºå¤±æ´»æ¯”ä¾‹ï¼š**", value=0.0,
                                                  min_value=0.0, max_value=0.8)
                        early = st.number_input("**æå‰ä¸­æ­¢æ³•éªŒè¯æ¯”ä¾‹ï¼š**",
                                                value=0.2, min_value=0.1,
                                                max_value=0.5)
                        optimizer = st.selectbox("**ä¼˜åŒ–å™¨ï¼š**",
                                                 ("adam", "sgd", "rmsprop",
                                                  "adadelta"))
                        batch = st.number_input("**æ‰¹æ¬¡å¤§å°ï¼š**",
                                                value=32, min_value=8)
                        epoch = st.number_input("**æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼š**",
                                                value=1000, min_value=100)
                        lstm_layers = st.number_input("**éšè—å±‚å±‚æ•°ï¼š**",
                                                      value=1, min_value=1,
                                                      disabled=True)
                        lstm_units = st.number_input("**éšè—å±‚èŠ‚ç‚¹æ•°ï¼š**",
                                                     value=8, min_value=1,
                                                     disabled=True)
                        submitted = st.form_submit_button('ç¡®å®šå¹¶è®­ç»ƒ')
            # è‹¥æœªæ£€æµ‹åˆ°æ•°æ®ï¼Œåˆ™ç¦ç”¨æ‰€æœ‰é€‰é¡¹å¹¶æç¤ºä¸Šä¼ å¤„ç†
            else:
                st.info('è¯·å®Œæˆæ•°æ®å¤„ç†ï¼', icon="â„¹ï¸")
                hp_option = st.selectbox("**è¯·é€‰æ‹©è¶…å‚æ•°è°ƒä¼˜æ–¹æ³•ï¼š**",
                                         ("ç½‘æ ¼æœç´¢", "éšæœºæœç´¢", "è´å¶æ–¯ä¼˜åŒ–",
                                          "Hyperband", "äººä¸ºæŒ‡å®š"), index=4,
                                         disabled=True)
                with st.form('lstm_form'):
                    seq_length = st.number_input("**æ—¶é—´æ­¥é•¿ï¼š**", value=7,
                                                 min_value=1, disabled=True)
                    act_option = st.selectbox("**éšè—å±‚æ¿€æ´»å‡½æ•°ï¼š**",
                                              ("relu", "tanh", "sigmoid",
                                               "linear", "exponential"),
                                              disabled=True)
                    dropout = st.number_input("**éšæœºå¤±æ´»æ¯”ä¾‹ï¼š**",
                                              value=0.0, min_value=0.0,
                                              max_value=0.8, disabled=True)
                    early = st.number_input("**æå‰ä¸­æ­¢æ³•éªŒè¯æ¯”ä¾‹ï¼š**",
                                            value=0.2, min_value=0.1,
                                            max_value=0.5, disabled=True)
                    optimizer = st.selectbox("**ä¼˜åŒ–å™¨ï¼š**",
                                             ("adam", "sgd", "rmsprop",
                                              "adadelta"), disabled=True)
                    batch = st.number_input("**æ‰¹æ¬¡å¤§å°ï¼š**", value=32,
                                            min_value=8, disabled=True)
                    epoch = st.number_input("**æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼š**",
                                            value=1000, min_value=100,
                                            disabled=True)
                    lstm_layers = st.number_input("**éšè—å±‚å±‚æ•°ï¼š**",
                                                  value=1, min_value=1,
                                                  disabled=True)
                    lstm_units = st.number_input("**éšè—å±‚èŠ‚ç‚¹æ•°ï¼š**",
                                                 value=8, min_value=1,
                                                 disabled=True)
                    submitted = st.form_submit_button('ç¡®å®šå¹¶è®­ç»ƒ', disabled=True)
    with st.container(border=True):
        # è®¾ç½®å­æ ‡é¢˜
        st.subheader('è®­ç»ƒç»“æœ')
        if submitted:
            with st.spinner('è®­ç»ƒä¸­ï¼Œè¯·ç¨å...'):
                # ä¿å­˜è®¾ç½®çš„æ—¶é—´æ­¥é•¿ä»¥ä¾¿äºåç»­å°†æ–°æ•°æ®è½¬æ¢ä¸ºä¸‰ä½å¼ é‡æ ¼å¼
                seq_frame = pd.DataFrame({'seq_length': [seq_length]})
                seq_frame.to_excel('Cache/sequence length.xlsx', index=False)
                # æ£€æŸ¥è®­ç»ƒæ•°æ®é›†ä¸­çš„è¾“å…¥å˜é‡æ•°æ®å’Œè¾“å‡ºå˜é‡æ•°æ®æ˜¯å¦å­˜åœ¨
                X_train_exists = check_sheet_exists(file_path='Cache/X train data.xlsx',
                                                    sheet_name='X')
                y_train_exists = check_sheet_exists(file_path='Cache/y train data.xlsx',
                                                    sheet_name='y')
                X_test_exists = check_sheet_exists(file_path='Cache/X test data.xlsx',
                                                   sheet_name='X')
                y_test_exists = check_sheet_exists(file_path='Cache/y test data.xlsx',
                                                   sheet_name='y')
                if X_train_exists and X_test_exists and y_train_exists and y_test_exists:
                    # ä»ç¼“å­˜ç›®å½•ä¸­è¯»å–è¾“å…¥æ•°æ®å¹¶è½¬æ¢æ ¼å¼ä»¥ä¾¿äºæ“ä½œ
                    X_train = pd.read_excel('Cache/X train data.xlsx',
                                            sheet_name='X')
                    X_test = pd.read_excel('Cache/X test data.xlsx',
                                           sheet_name='X')
                    X_train['æ—¶é—´'] = pd.to_datetime(X_train['æ—¶é—´'],
                                                   format='%Y-%m-%d %H:%M:%S')
                    X_test['æ—¶é—´'] = pd.to_datetime(X_test['æ—¶é—´'],
                                                  format='%Y-%m-%d %H:%M:%S')
                    X_train_index = X_train['æ—¶é—´']
                    X_test_index = X_test['æ—¶é—´']
                    X_train.index = X_train_index
                    X_test.index = X_test_index
                    X_train.drop(columns=['æ—¶é—´'], axis=1, inplace=True)
                    X_test.drop(columns=['æ—¶é—´'], axis=1, inplace=True)
                    X_colums = X_train.columns
                    # ä»ç¼“å­˜ç›®å½•ä¸­è¯»å–è¾“å‡ºæ•°æ®å¹¶è½¬æ¢æ ¼å¼ä»¥ä¾¿äºæ“ä½œ
                    y_train = pd.read_excel('Cache/y train data.xlsx',
                                            sheet_name='y')
                    y_test = pd.read_excel('Cache/y test data.xlsx',
                                           sheet_name='y')
                    y_train['æ—¶é—´'] = pd.to_datetime(y_train['æ—¶é—´'],
                                                   format='%Y-%m-%d %H:%M:%S')
                    y_test['æ—¶é—´'] = pd.to_datetime(y_test['æ—¶é—´'],
                                                  format='%Y-%m-%d %H:%M:%S')
                    y_train_index = y_train['æ—¶é—´']
                    y_test_index = y_test['æ—¶é—´']
                    y_train.index = y_train_index
                    y_test.index = y_test_index
                    y_train.drop(columns=['æ—¶é—´'], axis=1, inplace=True)
                    y_test.drop(columns=['æ—¶é—´'], axis=1, inplace=True)
                    y_colums = y_train.columns
                    # å°†DataFrameè½¬æ¢ä¸ºNumpyæ•°ç»„æ ¼å¼ä»¥ä¾¿äºåç»­æ•°æ®å½¢å¼è½¬æ¢
                    X_train = np.array(X_train)
                    y_train = np.array(y_train)
                    X_test = np.array(X_test)
                    y_test = np.array(y_test)
                    # å°†æ•°æ®è½¬æ¢ä¸ºåºåˆ—æ ¼å¼
                    X_train, y_train = create_sequences(X_train, y_train,
                                                        seq_length)
                    X_test, y_test = create_sequences(X_test, y_test,
                                                      seq_length)
                    # è‹¥é€‰æ‹©äººä¸ºæŒ‡å®šè¶…å‚æ•°ï¼Œåˆ™æ ¹æ®æŒ‡å®šçš„è¶…å‚æ•°è®­ç»ƒæ¨¡å‹
                    if hp_option == "äººä¸ºæŒ‡å®š":
                        lstm = Sequential()
                        if lstm_layers == 1:
                            lstm.add(LSTM(units=lstm_units,
                                          activation=act_option,
                                          input_shape=(seq_length,
                                                       len(X_colums))))
                        else:
                            for i in range(lstm_layers):
                                if i == 0:
                                    lstm.add(LSTM(units=lstm_units,
                                                  activation=act_option,
                                                  input_shape=(seq_length,
                                                               len(X_colums)),
                                                  return_sequences=True))
                                elif i == lstm_layers-1:
                                    lstm.add(LSTM(units=lstm_units,
                                                  activation=act_option))
                                else:
                                    lstm.add(LSTM(units=lstm_units,
                                                  activation=act_option,
                                                  dropout=dropout,
                                                  return_sequences=True))
                        lstm.add(Dense(units=len(y_colums)))
                        early_stop = EarlyStopping(monitor='val_loss',
                                                   patience=10,
                                                   restore_best_weights=True)
                        lstm.compile(optimizer=optimizer, loss='mse')
                        history = lstm.fit(X_train, y_train, epochs=epoch,
                                           batch_size=batch,
                                           validation_split=early,
                                           callbacks=[early_stop])
                        # å‚¨å­˜æ¨¡å‹
                        lstm.save('Cache/model/LSTM.keras')
                        # åˆ†åˆ«åœ¨è®­ç»ƒé›†å’Œæµ‹è¯•é›†ä¸­é¢„æµ‹
                        y_train_pred = lstm.predict(X_train)
                        y_test_pred = lstm.predict(X_test)
                        # å°†æ•°æ®æ ¼å¼è½¬æ¢ä¸ºDataFrame
                        hist = pd.DataFrame(history.history)
                        y_train_pred = pd.DataFrame(y_train_pred)
                        y_test_pred = pd.DataFrame(y_test_pred)
                        y_train = pd.DataFrame(y_train, columns=y_colums)
                        y_test = pd.DataFrame(y_test, columns=y_colums)
                        # å°†æ•°æ®å‚¨å­˜åœ¨ç¼“å­˜ç›®å½•ä»¥ä¾¿äºåç»­ä½¿ç”¨å’Œè®¡ç®—
                        with pd.ExcelWriter('Cache/history/LSTM results.xlsx') as writer:
                            hist.to_excel(writer, index=False,
                                          sheet_name='hist')
                            y_train_pred.to_excel(writer, index=False,
                                                  sheet_name='trainpred')
                            y_test_pred.to_excel(writer, index=False,
                                                 sheet_name='testpred')
                            y_train.to_excel(writer, index=False,
                                             sheet_name='train')
                            y_test.to_excel(writer, index=False,
                                            sheet_name='test')
                    # è‹¥é€‰æ‹©è¶…å‚æ•°è°ƒä¼˜æ–¹æ³•ï¼Œåˆ™æ ¹æ®é€‰æ‹©çš„æ–¹æ³•æœç´¢è¶…å‚æ•°å¹¶è®­ç»ƒæ¨¡å‹
                    else:
                        def create_model(hp):
                            hp_units = hp.Int('lstm_units', min_value=32,
                                              max_value=512, step=8)
                            hp_layers = hp.Int('lstm_layers', min_value=1,
                                               max_value=10, step=1)
                            lstm = Sequential()
                            if hp_layers == 1:
                                lstm.add(LSTM(units=hp_units,
                                              activation=act_option,
                                              input_shape=(seq_length,
                                                           len(X_colums))))
                            else:
                                for i in range(hp_layers):
                                    if i == 0:
                                        lstm.add(LSTM(units=hp_units,
                                                      activation=act_option,
                                                      input_shape=(seq_length,
                                                                   len(X_colums)),
                                                      return_sequences=True))
                                    elif i == hp_layers-1:
                                        lstm.add(LSTM(units=hp_units,
                                                      activation=act_option))
                                    else:
                                        lstm.add(LSTM(units=hp_units,
                                                      dropout=dropout,
                                                      activation=act_option,
                                                      return_sequences=True))
                            lstm.add(Dense(units=len(y_colums)))
                            lstm.compile(optimizer=optimizer, loss='mse')
                            return lstm
                        if hp_option == "ç½‘æ ¼æœç´¢":
                            tuner = kt.GridSearch(create_model,
                                                  objective='val_loss',
                                                  directory='Cache/hp tuning',
                                                  project_name='LSTM GridSearch')
                        elif hp_option == "éšæœºæœç´¢":
                            tuner = kt.RandomSearch(create_model,
                                                    max_trials=epoch,
                                                    objective='val_loss',
                                                    directory='Cache/hp tuning',
                                                    project_name='LSTM RandomSearch')
                        elif hp_option == "è´å¶æ–¯ä¼˜åŒ–":
                            tuner = kt.BayesianOptimization(create_model,
                                                            max_trials=epoch,
                                                            objective='val_loss',
                                                            directory='Cache/hp tuning',
                                                            project_name='LSTM Bayesian')
                        elif hp_option == "Hyperband":
                            tuner = kt.Hyperband(create_model, max_epochs=epoch,
                                                 objective='val_loss',
                                                 directory='Cache/hp tuning',
                                                 project_name='LSTM Hyperband')
                        early_stop = EarlyStopping(monitor='val_loss',
                                                   patience=10,
                                                   restore_best_weights=True)
                        tuner.search(X_train, y_train, validation_split=early,
                                     epochs=epoch, batch_size=batch,
                                     callbacks=[early_stop])
                        best_hps = tuner.get_best_hyperparameters()[0]
                        st.toast(best_hps.values)
                        # è·å–æ‹¥æœ‰æœ€ä½³è¶…å‚æ•°çš„æ¨¡å‹å¹¶ä¿å­˜
                        best_lstm = tuner.get_best_models()[0]
                        best_lstm.save('Cache/model/LSTM.keras')
                        # åˆ†åˆ«åœ¨è®­ç»ƒé›†å’Œæµ‹è¯•é›†ä¸­é¢„æµ‹
                        y_train_pred = best_lstm.predict(X_train)
                        y_test_pred = best_lstm.predict(X_test)
                        # å°†æ•°æ®æ ¼å¼è½¬æ¢ä¸ºDataFrame
                        hist = pd.DataFrame(history.history)
                        y_train_pred = pd.DataFrame(y_train_pred)
                        y_test_pred = pd.DataFrame(y_test_pred)
                        y_train = pd.DataFrame(y_train, columns=y_colums)
                        y_test = pd.DataFrame(y_test, columns=y_colums)
                        # å°†æ•°æ®å‚¨å­˜åœ¨ç¼“å­˜ç›®å½•ä»¥ä¾¿äºåç»­ä½¿ç”¨å’Œè®¡ç®—
                        with pd.ExcelWriter('Cache/history/LSTM results.xlsx') as writer:
                            hist.to_excel(writer, index=False,
                                          sheet_name='hist')
                            y_train_pred.to_excel(writer, index=False,
                                                  sheet_name='trainpred')
                            y_test_pred.to_excel(writer, index=False,
                                                 sheet_name='testpred')
                            y_train.to_excel(writer, index=False,
                                             sheet_name='train')
                            y_test.to_excel(writer, index=False,
                                            sheet_name='test')
        # å¸ƒå±€ï¼Œå°†è®­ç»ƒç»“æœå’Œæµ‹è¯•ç»“æœåˆ†æˆå·¦å³ä¸¤éƒ¨åˆ†æ˜¾ç¤º
        col_train, col_test = st.columns(2, gap="large")
        # å·¦éƒ¨åˆ†æ˜¾ç¤ºæµ‹è¯•æ•°æ®ä¸­çš„è¾“å…¥å˜é‡
        with col_train:
            hist_exists = check_sheet_exists(file_path='Cache/history/LSTM results.xlsx',
                                             sheet_name='hist')
            trainpred_exists = check_sheet_exists(file_path='Cache/history/LSTM results.xlsx',
                                                  sheet_name='trainpred')
            testpred_exists = check_sheet_exists(file_path='Cache/history/LSTM results.xlsx',
                                                 sheet_name='testpred')
            train_exists = check_sheet_exists(file_path='Cache/history/LSTM results.xlsx',
                                              sheet_name='train')
            test_exists = check_sheet_exists(file_path='Cache/history/LSTM results.xlsx',
                                             sheet_name='test')
            # æ£€æŸ¥è®­ç»ƒå†å²è®°å½•æ˜¯å¦å­˜åœ¨
            if hist_exists:
                st.success("å·²æ£€æµ‹åˆ°è®­ç»ƒå†å²è®°å½•ï¼", icon="âœ…")
                # ç»˜åˆ¶è®­ç»ƒçš„Losså›¾
                hist = pd.read_excel('Cache/history/LSTM results.xlsx',
                                     sheet_name='hist')
                st.caption('è®­ç»ƒè¿‡ç¨‹çš„Losså›¾ï¼š')
                st.line_chart(hist, x_label="Epoch", y_label="Loss")
                # æ£€æŸ¥è®­ç»ƒé›†çš„è¾“å‡ºå’Œé¢„æµ‹æ˜¯å¦å­˜åœ¨
                if trainpred_exists and train_exists:
                    # å¯¼å…¥æ‰€éœ€æ•°æ®
                    y_train_pred = pd.read_excel('Cache/history/LSTM results.xlsx',
                                                 sheet_name='trainpred')
                    y_train = pd.read_excel('Cache/history/LSTM results.xlsx',
                                            sheet_name='train')
                    y_colums = y_train.columns
                    # å°†DataFrameè½¬æ¢ä¸ºNumpyæ•°ç»„ä»¥ä¾¿äºåç»­åˆ‡ç‰‡
                    y_train_pred = np.array(y_train_pred)
                    y_train = np.array(y_train)
                    # æ¨¡å‹æ€§èƒ½è¯„ä¼°ï¼šè®­ç»ƒé›†ä¸­çš„R2
                    r2_train = []
                    for i in range(y_train.shape[1]):
                        r2_train_i = metrics.r2_score(y_train[:, i], y_train_pred[:, i])
                        r2_train.append(r2_train_i)
                    # ä»ç¼“å­˜ç›®å½•ä¸­è¯»å–æ ‡å‡†åŒ–å‰çš„æ•°æ®
                    data = pd.read_excel('Cache/imputed data.xlsx',
                                         sheet_name='filled')
                    # è½¬æ¢æ—¶é—´æ ¼å¼
                    data['æ—¶é—´'] = pd.to_datetime(data['æ—¶é—´'],
                                                format='%Y-%m-%d %H:%M:%S')
                    # æå–æ—¶é—´ä¿¡æ¯å¹¶å°†æ—¶é—´ä¿¡æ¯è½¬æ¢ä¸ºç´¢å¼•
                    data_index = data['æ—¶é—´']
                    data.index = data_index
                    # åˆ é™¤å¤šä½™çš„æ—¶é—´åˆ—å¹¶æå–è¾“å‡ºå˜é‡
                    data.drop(columns=['æ—¶é—´'], axis=1, inplace=True)
                    y_data = data[y_colums]
                    # ä»ç¼“å­˜ç›®å½•ä¸­åŠ è½½æ ‡å‡†åŒ–æ–¹æ³•
                    with open('Cache/scaler.pkl', 'rb') as f:
                        scaler = pickle.load(f)
                    # æ‹Ÿåˆæ ‡å‡†åŒ–æ–¹æ³•ä¸ºåæ ‡å‡†åŒ–åšå‡†å¤‡
                    y_scaled = scaler.fit_transform(y_data)
                    # å¯¹è¾“å‡ºå˜é‡çš„çœŸå®å€¼å’Œé¢„æµ‹å€¼è¿›è¡Œåæ ‡å‡†åŒ–
                    y_train = scaler.inverse_transform(y_train)
                    y_train_pred = scaler.inverse_transform(y_train_pred)
                    # æ¨¡å‹æ€§èƒ½è¯„ä¼°ï¼šè®­ç»ƒé›†ä¸­çš„MAE
                    mae_train = []
                    for i in range(y_train.shape[1]):
                        mae_train_i = metrics.mean_absolute_error(y_train[:, i], y_train_pred[:, i])
                        mae_train.append(mae_train_i)
                    # æ¨¡å‹æ€§èƒ½è¯„ä¼°ï¼šè®­ç»ƒé›†ä¸­çš„MSE    
                    mse_train = []
                    for i in range(y_train.shape[1]):
                        mse_train_i = metrics.mean_squared_error(y_train[:, i], y_train_pred[:, i])
                        mse_train.append(mse_train_i)
                    # å°†æ‰€æœ‰ç»“æœè½¬æ¢ä¸ºDataFrameæ ¼å¼ä»¥ä¾¿äºå‰ç«¯å±•ç¤º
                    r2_train = pd.DataFrame(r2_train, columns=['R2'])
                    mae_train = pd.DataFrame(mae_train, columns=['MAE'])
                    mse_train = pd.DataFrame(mse_train, columns=['MSE'])
                    # æ±‡æ€»ç»“æœ
                    train_result = pd.concat([r2_train, mae_train,
                                              mse_train], axis=1)
                    train_result.index = y_colums
                    train_result = train_result.T
                    # åœ¨å‰ç«¯æ˜¾ç¤ºç»“æœ
                    st.caption('æ¨¡å‹çš„è®­ç»ƒç»“æœå¦‚ä¸‹æ‰€ç¤ºï¼š')
                    st.dataframe(train_result, use_container_width=True)
                # è‹¥è®­ç»ƒé›†çš„è¾“å‡ºå’Œé¢„æµ‹ä¸å­˜åœ¨ï¼Œåˆ™æç¤º
                else:
                    st.caption('æ¨¡å‹çš„è®­ç»ƒç»“æœå¦‚ä¸‹æ‰€ç¤ºï¼š')
                    st.info('æœªæ£€æµ‹åˆ°è®­ç»ƒç»“æœï¼', icon="â„¹ï¸")
            # è‹¥è®­ç»ƒå†å²è®°å½•ä¸å­˜åœ¨ï¼Œåˆ™æç¤º
            else:
                st.caption('è®­ç»ƒè¿‡ç¨‹çš„Losså›¾ï¼š')
                st.info('æœªæ£€æµ‹åˆ°è®­ç»ƒå†å²ï¼', icon="â„¹ï¸")
                st.caption('æ¨¡å‹çš„è®­ç»ƒç»“æœå¦‚ä¸‹æ‰€ç¤ºï¼š')
                st.info('è¯·å…ˆè®­ç»ƒæ¨¡å‹ï¼', icon="â„¹ï¸")
        # å³éƒ¨åˆ†æ˜¾ç¤ºæµ‹è¯•æ•°æ®ä¸­çš„è¾“å‡ºå˜é‡
        with col_test:
            if testpred_exists and test_exists:
                # ç»˜åˆ¶è®­ç»ƒçš„Losså›¾
                st.success("å·²æ£€æµ‹åˆ°æ¨¡å‹æµ‹è¯•ç»“æœï¼", icon="âœ…")
                st.caption('æµ‹è¯•è¿‡ç¨‹ä¸­é¢„æµ‹å€¼ä¸çœŸå®å€¼çš„å¯¹æ¯”ï¼š')
                y_test_pred = pd.read_excel('Cache/history/LSTM results.xlsx',
                                            sheet_name='testpred')
                y_test = pd.read_excel('Cache/history/LSTM results.xlsx',
                                       sheet_name='test')
                y_colums = y_test.columns
                y_test_pred = np.array(y_test_pred)
                y_test = np.array(y_test)
                data_dict = {}
                column_names = []
                for i in range(len(y_colums)):
                    true_name = f"çœŸå®å€¼_{i}"
                    pred_name = f"é¢„æµ‹å€¼_{i}"
                    column_names.extend([true_name, pred_name])
                    data_dict[true_name] = y_test[:, i]
                    data_dict[pred_name] = y_test_pred[:, i]
                    chart_data = pd.DataFrame(data_dict)
                st.line_chart(chart_data, x_label="æ—¶é—´", y_label="æ ‡å‡†åŒ–å€¼")
                # æ¨¡å‹æ€§èƒ½è¯„ä¼°ï¼šæµ‹è¯•é›†ä¸­çš„R2
                r2_test = []
                for i in range(y_test.shape[1]):
                    r2_test_i = metrics.r2_score(y_test[:, i], y_test_pred[:, i])
                    r2_test.append(r2_test_i)
                # ä»ç¼“å­˜ç›®å½•ä¸­è¯»å–æ ‡å‡†åŒ–å‰çš„æ•°æ®
                data = pd.read_excel('Cache/imputed data.xlsx',
                                     sheet_name='filled')
                # è½¬æ¢æ—¶é—´æ ¼å¼
                data['æ—¶é—´'] = pd.to_datetime(data['æ—¶é—´'],
                                            format='%Y-%m-%d %H:%M:%S')
                # æå–æ—¶é—´ä¿¡æ¯å¹¶å°†æ—¶é—´ä¿¡æ¯è½¬æ¢ä¸ºç´¢å¼•
                data_index = data['æ—¶é—´']
                data.index = data_index
                # åˆ é™¤å¤šä½™çš„æ—¶é—´åˆ—å¹¶æå–è¾“å‡ºå˜é‡
                data.drop(columns=['æ—¶é—´'], axis=1, inplace=True)
                y_data = data[y_colums]
                # ä»ç¼“å­˜ç›®å½•ä¸­åŠ è½½æ ‡å‡†åŒ–æ–¹æ³•
                with open('Cache/scaler.pkl', 'rb') as f:
                    scaler = pickle.load(f)
                # æ‹Ÿåˆæ ‡å‡†åŒ–æ–¹æ³•ä¸ºåæ ‡å‡†åŒ–åšå‡†å¤‡
                y_scaled = scaler.fit_transform(y_data)
                # å¯¹è¾“å‡ºå˜é‡çš„çœŸå®å€¼å’Œé¢„æµ‹å€¼è¿›è¡Œåæ ‡å‡†åŒ–
                y_test = scaler.inverse_transform(y_test)
                y_test_pred = scaler.inverse_transform(y_test_pred)
                # æ¨¡å‹æ€§èƒ½è¯„ä¼°ï¼šæµ‹è¯•é›†ä¸­çš„MAE
                mae_test = []
                for i in range(y_test.shape[1]):
                    mae_test_i = metrics.mean_absolute_error(y_test[:, i],
                                                             y_test_pred[:, i])
                    mae_test.append(mae_test_i)
                # æ¨¡å‹æ€§èƒ½è¯„ä¼°ï¼šæµ‹è¯•é›†ä¸­çš„MSE
                mse_test = []
                for i in range(y_test.shape[1]):
                    mse_test_i = metrics.mean_squared_error(y_test[:, i],
                                                            y_test_pred[:, i])
                    mse_test.append(mse_test_i)
                # å°†æ‰€æœ‰ç»“æœè½¬æ¢ä¸ºDataFrameæ ¼å¼ä»¥ä¾¿äºå‰ç«¯å±•ç¤º
                r2_test = pd.DataFrame(r2_test, columns=['R2'])
                mae_test = pd.DataFrame(mae_test, columns=['MAE'])
                mse_test = pd.DataFrame(mse_test, columns=['MSE'])
                # æ±‡æ€»ç»“æœ
                test_result = pd.concat([r2_test, mae_test,
                                         mse_test], axis=1)
                test_result.index = y_colums
                test_result = test_result.T
                # åœ¨å‰ç«¯æ˜¾ç¤ºç»“æœ
                st.caption('æ¨¡å‹çš„æµ‹è¯•ç»“æœå¦‚ä¸‹æ‰€ç¤ºï¼š')
                st.dataframe(test_result, use_container_width=True)
            # è‹¥æµ‹è¯•ç»“æœè®°å½•ä¸å­˜åœ¨ï¼Œåˆ™æç¤º
            else:
                st.caption('æµ‹è¯•è¿‡ç¨‹ä¸­é¢„æµ‹å€¼ä¸çœŸå®å€¼çš„å¯¹æ¯”ï¼š')
                st.info('æœªæ£€æµ‹åˆ°æµ‹è¯•ç»“æœï¼', icon="â„¹ï¸")
                st.caption('æ¨¡å‹çš„è®­ç»ƒç»“æœå¦‚ä¸‹æ‰€ç¤ºï¼š')
                st.info('è¯·å…ˆè®­ç»ƒæ¨¡å‹ï¼', icon="â„¹ï¸")
# ç¬¬ä¸‰éƒ¨åˆ†çš„ç¬¬ä¸‰é¡µï¼šGRUæ¨¡å‹
def page_33():
    with st.container(border=True):
        # è®¾ç½®å­æ ‡é¢˜
        st.subheader('*é—¨æ§å¾ªç¯å•å…ƒï¼ˆGRUï¼‰*')
        with st.spinner('æ£€æµ‹æ•°æ®ä¸­ï¼Œè¯·ç¨å...'):
            # æ£€æŸ¥æ•°æ®æ˜¯å¦å­˜åœ¨
            X_train_exists = check_sheet_exists(file_path='Cache/X train data.xlsx',
                                                sheet_name='X')
            y_train_exists = check_sheet_exists(file_path='Cache/y train data.xlsx',
                                                sheet_name='y')
            X_test_exists = check_sheet_exists(file_path='Cache/X test data.xlsx',
                                               sheet_name='X')
            y_test_exists = check_sheet_exists(file_path='Cache/y test data.xlsx',
                                               sheet_name='y')
            if X_train_exists and X_test_exists and y_train_exists and y_test_exists:
                # æç¤ºæˆåŠŸæ£€æµ‹
                st.success("å·²æ£€æµ‹åˆ°åˆ’åˆ†çš„è®­ç»ƒé›†å’Œæµ‹è¯•é›†ï¼è¯·æ‚¨æŒ‰ç…§æµç¨‹å®Œæˆè®­ç»ƒï¼", icon="âœ…")
                # è¦æ±‚ç”¨æˆ·é€‰æ‹©è¶…å‚æ•°è°ƒä¼˜æ–¹æ³•
                hp_option = st.selectbox("**è¯·é€‰æ‹©è¶…å‚æ•°è°ƒä¼˜æ–¹æ³•ï¼š**",
                                         ("ç½‘æ ¼æœç´¢", "éšæœºæœç´¢", "è´å¶æ–¯ä¼˜åŒ–",
                                          "Hyperband", "äººä¸ºæŒ‡å®š"), index=4)
                # å¦‚æœé€‰æ‹©äººä¸ºæŒ‡å®šï¼Œåˆ™æ¿€æ´»æ‰€æœ‰åŠŸèƒ½
                if hp_option == "äººä¸ºæŒ‡å®š":
                    # è®¾ç½®æäº¤è¡¨å•
                    with st.form('gru_form'):
                        # è¦æ±‚ç”¨æˆ·é€‰æ‹©æ—¶é—´æ­¥é•¿
                        seq_length = st.number_input("**æ—¶é—´æ­¥é•¿ï¼š**", value=7,
                                                     min_value=1)
                        # è¦æ±‚ç”¨æˆ·é€‰æ‹©æ¿€æ´»å‡½æ•°
                        act_option = st.selectbox("**éšè—å±‚æ¿€æ´»å‡½æ•°ï¼š**",
                                                  ("relu", "tanh", "sigmoid",
                                                   "linear", "exponential"))
                        # è¦æ±‚ç”¨æˆ·æŒ‡å®šéšæœºå¤±æ´»
                        dropout = st.number_input("**éšæœºå¤±æ´»æ¯”ä¾‹ï¼š**", value=0.0,
                                                  min_value=0.0, max_value=0.8)
                        # è¦æ±‚ç”¨æˆ·ä¸ºæå‰ç»ˆæ­¢æ³•æŒ‡å®šéªŒè¯æ¯”ä¾‹
                        early = st.number_input("**æå‰ç»ˆæ­¢æ³•éªŒè¯æ¯”ä¾‹ï¼š**",
                                                value=0.2, min_value=0.1,
                                                max_value=0.5)
                        # è¦æ±‚ç”¨æˆ·é€‰æ‹©ä¼˜åŒ–å™¨
                        optimizer = st.selectbox("**ä¼˜åŒ–å™¨ï¼š**",
                                                 ("adam", "sgd", "rmsprop",
                                                  "adadelta"))
                        # è¦æ±‚ç”¨æˆ·æŒ‡å®šæ‰¹æ¬¡å¤§å°
                        batch = st.number_input("**æ‰¹æ¬¡å¤§å°ï¼š**",
                                                value=32, min_value=8)
                        # è¦æ±‚ç”¨æˆ·æŒ‡å®šæœ€å¤§è¿­ä»£æ¬¡æ•°
                        epoch = st.number_input("**æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼š**",
                                                value=1000, min_value=100)
                        # è‹¥è¶…å‚æ•°è°ƒä¼˜æ–¹æ³•é€‰æ‹©äººå·¥æŒ‡å®šåˆ™è¦æ±‚ç”¨æˆ·é€‰æ‹©GRUçš„èŠ‚ç‚¹æ•°å’Œå±‚æ•°
                        gru_layers = st.number_input("**éšè—å±‚å±‚æ•°ï¼š**",
                                                     value=1, min_value=1)
                        gru_units = st.number_input("**éšè—å±‚èŠ‚ç‚¹æ•°ï¼š**",
                                                    value=8, min_value=1)
                        # è®¾ç½®æäº¤æŒ‰é’®
                        submitted = st.form_submit_button('ç¡®å®šå¹¶è®­ç»ƒ')
                # å¦‚æœä½¿ç”¨æœç´¢æ–¹æ³•ï¼Œåˆ™ç¦ç”¨ä¸€éƒ¨åˆ†åŠŸèƒ½
                else:
                    # è®¾ç½®æäº¤è¡¨å•
                    with st.form('gru_form'):
                        seq_length = st.number_input("**æ—¶é—´æ­¥é•¿ï¼š**", value=7,
                                                     min_value=1)
                        act_option = st.selectbox("**éšè—å±‚æ¿€æ´»å‡½æ•°ï¼š**",
                                                  ("relu", "tanh", "sigmoid",
                                                   "linear", "exponential"))
                        dropout = st.number_input("**éšæœºå¤±æ´»æ¯”ä¾‹ï¼š**", value=0.0,
                                                  min_value=0.0, max_value=0.8)
                        early = st.number_input("**æå‰ä¸­æ­¢æ³•éªŒè¯æ¯”ä¾‹ï¼š**",
                                                value=0.2, min_value=0.1,
                                                max_value=0.5)
                        optimizer = st.selectbox("**ä¼˜åŒ–å™¨ï¼š**",
                                                 ("adam", "sgd", "rmsprop",
                                                  "adadelta"))
                        batch = st.number_input("**æ‰¹æ¬¡å¤§å°ï¼š**",
                                                value=32, min_value=8)
                        epoch = st.number_input("**æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼š**",
                                                value=1000, min_value=100)
                        gru_layers = st.number_input("**éšè—å±‚å±‚æ•°ï¼š**",
                                                     value=1, min_value=1,
                                                     disabled=True)
                        gru_units = st.number_input("**éšè—å±‚èŠ‚ç‚¹æ•°ï¼š**",
                                                    value=8, min_value=1,
                                                    disabled=True)
                        submitted = st.form_submit_button('ç¡®å®šå¹¶è®­ç»ƒ')
            # è‹¥æœªæ£€æµ‹åˆ°æ•°æ®ï¼Œåˆ™ç¦ç”¨æ‰€æœ‰é€‰é¡¹å¹¶æç¤ºä¸Šä¼ å¤„ç†
            else:
                st.info('è¯·å®Œæˆæ•°æ®å¤„ç†ï¼', icon="â„¹ï¸")
                hp_option = st.selectbox("**è¯·é€‰æ‹©è¶…å‚æ•°è°ƒä¼˜æ–¹æ³•ï¼š**",
                                         ("ç½‘æ ¼æœç´¢", "éšæœºæœç´¢", "è´å¶æ–¯ä¼˜åŒ–",
                                          "Hyperband", "äººä¸ºæŒ‡å®š"), index=4,
                                         disabled=True)
                with st.form('gru_form'):
                    seq_length = st.number_input("**æ—¶é—´æ­¥é•¿ï¼š**", value=7,
                                                 min_value=1, disabled=True)
                    act_option = st.selectbox("**éšè—å±‚æ¿€æ´»å‡½æ•°ï¼š**",
                                              ("relu", "tanh", "sigmoid",
                                               "linear", "exponential"),
                                              disabled=True)
                    dropout = st.number_input("**éšæœºå¤±æ´»æ¯”ä¾‹ï¼š**",
                                              value=0.0, min_value=0.0,
                                              max_value=0.8, disabled=True)
                    early = st.number_input("**æå‰ä¸­æ­¢æ³•éªŒè¯æ¯”ä¾‹ï¼š**",
                                            value=0.2, min_value=0.1,
                                            max_value=0.5, disabled=True)
                    optimizer = st.selectbox("**ä¼˜åŒ–å™¨ï¼š**",
                                             ("adam", "sgd", "rmsprop",
                                              "adadelta"), disabled=True)
                    batch = st.number_input("**æ‰¹æ¬¡å¤§å°ï¼š**", value=32,
                                            min_value=8, disabled=True)
                    epoch = st.number_input("**æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼š**",
                                            value=1000, min_value=100,
                                            disabled=True)
                    gru_layers = st.number_input("**éšè—å±‚å±‚æ•°ï¼š**",
                                                 value=1, min_value=1,
                                                 disabled=True)
                    gru_units = st.number_input("**éšè—å±‚èŠ‚ç‚¹æ•°ï¼š**",
                                                value=8, min_value=1,
                                                disabled=True)
                    submitted = st.form_submit_button('ç¡®å®šå¹¶è®­ç»ƒ', disabled=True)
    with st.container(border=True):
        # è®¾ç½®å­æ ‡é¢˜
        st.subheader('è®­ç»ƒç»“æœ')
        if submitted:
            with st.spinner('è®­ç»ƒä¸­ï¼Œè¯·ç¨å...'):
                # ä¿å­˜è®¾ç½®çš„æ—¶é—´æ­¥é•¿ä»¥ä¾¿äºåç»­å°†æ–°æ•°æ®è½¬æ¢ä¸ºä¸‰ä½å¼ é‡æ ¼å¼
                seq_frame = pd.DataFrame({'seq_length': [seq_length]})
                seq_frame.to_excel('Cache/sequence length.xlsx', index=False)
                # æ£€æŸ¥è®­ç»ƒæ•°æ®é›†ä¸­çš„è¾“å…¥å˜é‡æ•°æ®å’Œè¾“å‡ºå˜é‡æ•°æ®æ˜¯å¦å­˜åœ¨
                X_train_exists = check_sheet_exists(file_path='Cache/X train data.xlsx',
                                                    sheet_name='X')
                y_train_exists = check_sheet_exists(file_path='Cache/y train data.xlsx',
                                                    sheet_name='y')
                X_test_exists = check_sheet_exists(file_path='Cache/X test data.xlsx',
                                                   sheet_name='X')
                y_test_exists = check_sheet_exists(file_path='Cache/y test data.xlsx',
                                                   sheet_name='y')
                if X_train_exists and X_test_exists and y_train_exists and y_test_exists:
                    # ä»ç¼“å­˜ç›®å½•ä¸­è¯»å–è¾“å…¥æ•°æ®å¹¶è½¬æ¢æ ¼å¼ä»¥ä¾¿äºæ“ä½œ
                    X_train = pd.read_excel('Cache/X train data.xlsx',
                                            sheet_name='X')
                    X_test = pd.read_excel('Cache/X test data.xlsx',
                                           sheet_name='X')
                    X_train['æ—¶é—´'] = pd.to_datetime(X_train['æ—¶é—´'],
                                                   format='%Y-%m-%d %H:%M:%S')
                    X_test['æ—¶é—´'] = pd.to_datetime(X_test['æ—¶é—´'],
                                                  format='%Y-%m-%d %H:%M:%S')
                    X_train_index = X_train['æ—¶é—´']
                    X_test_index = X_test['æ—¶é—´']
                    X_train.index = X_train_index
                    X_test.index = X_test_index
                    X_train.drop(columns=['æ—¶é—´'], axis=1, inplace=True)
                    X_test.drop(columns=['æ—¶é—´'], axis=1, inplace=True)
                    X_colums = X_train.columns
                    # ä»ç¼“å­˜ç›®å½•ä¸­è¯»å–è¾“å‡ºæ•°æ®å¹¶è½¬æ¢æ ¼å¼ä»¥ä¾¿äºæ“ä½œ
                    y_train = pd.read_excel('Cache/y train data.xlsx',
                                            sheet_name='y')
                    y_test = pd.read_excel('Cache/y test data.xlsx',
                                           sheet_name='y')
                    y_train['æ—¶é—´'] = pd.to_datetime(y_train['æ—¶é—´'],
                                                   format='%Y-%m-%d %H:%M:%S')
                    y_test['æ—¶é—´'] = pd.to_datetime(y_test['æ—¶é—´'],
                                                  format='%Y-%m-%d %H:%M:%S')
                    y_train_index = y_train['æ—¶é—´']
                    y_test_index = y_test['æ—¶é—´']
                    y_train.index = y_train_index
                    y_test.index = y_test_index
                    y_train.drop(columns=['æ—¶é—´'], axis=1, inplace=True)
                    y_test.drop(columns=['æ—¶é—´'], axis=1, inplace=True)
                    y_colums = y_train.columns
                    # å°†DataFrameè½¬æ¢ä¸ºNumpyæ•°ç»„æ ¼å¼ä»¥ä¾¿äºåç»­æ•°æ®å½¢å¼è½¬æ¢
                    X_train = np.array(X_train)
                    y_train = np.array(y_train)
                    X_test = np.array(X_test)
                    y_test = np.array(y_test)
                    # å°†æ•°æ®è½¬æ¢ä¸ºåºåˆ—æ ¼å¼
                    X_train, y_train = create_sequences(X_train, y_train,
                                                        seq_length)
                    X_test, y_test = create_sequences(X_test, y_test,
                                                      seq_length)
                    # è‹¥é€‰æ‹©äººä¸ºæŒ‡å®šè¶…å‚æ•°ï¼Œåˆ™æ ¹æ®æŒ‡å®šçš„è¶…å‚æ•°è®­ç»ƒæ¨¡å‹
                    if hp_option == "äººä¸ºæŒ‡å®š":
                        gru = Sequential()
                        if gru_layers == 1:
                            gru.add(GRU(units=gru_units, activation=act_option,
                                        input_shape=(seq_length,
                                                     len(X_colums))))
                        else:
                            for i in range(gru_layers):
                                if i == 0:
                                    gru.add(GRU(units=gru_units,
                                                activation=act_option,
                                                input_shape=(seq_length,
                                                             len(X_colums)),
                                                return_sequences=True))
                                elif i == gru_layers-1:
                                    gru.add(GRU(units=gru_units,
                                                activation=act_option))
                                else:
                                    gru.add(GRU(units=gru_units,
                                                activation=act_option,
                                                dropout=dropout,
                                                return_sequences=True))
                        gru.add(Dense(units=len(y_colums)))
                        early_stop = EarlyStopping(monitor='val_loss',
                                                   patience=10,
                                                   restore_best_weights=True)
                        gru.compile(optimizer=optimizer, loss='mse')
                        history = gru.fit(X_train, y_train, epochs=epoch,
                                          batch_size=batch,
                                          validation_split=early,
                                          callbacks=[early_stop])
                        # å‚¨å­˜æ¨¡å‹
                        gru.save('Cache/model/GRU.keras')
                        # åˆ†åˆ«åœ¨è®­ç»ƒé›†å’Œæµ‹è¯•é›†ä¸­é¢„æµ‹
                        y_train_pred = gru.predict(X_train)
                        y_test_pred = gru.predict(X_test)
                        # å°†æ•°æ®æ ¼å¼è½¬æ¢ä¸ºDataFrame
                        hist = pd.DataFrame(history.history)
                        y_train_pred = pd.DataFrame(y_train_pred)
                        y_test_pred = pd.DataFrame(y_test_pred)
                        y_train = pd.DataFrame(y_train, columns=y_colums)
                        y_test = pd.DataFrame(y_test, columns=y_colums)
                        # å°†æ•°æ®å‚¨å­˜åœ¨ç¼“å­˜ç›®å½•ä»¥ä¾¿äºåç»­ä½¿ç”¨å’Œè®¡ç®—
                        with pd.ExcelWriter('Cache/history/GRU results.xlsx') as writer:
                            hist.to_excel(writer, index=False,
                                          sheet_name='hist')
                            y_train_pred.to_excel(writer, index=False,
                                                  sheet_name='trainpred')
                            y_test_pred.to_excel(writer, index=False,
                                                 sheet_name='testpred')
                            y_train.to_excel(writer, index=False,
                                             sheet_name='train')
                            y_test.to_excel(writer, index=False,
                                            sheet_name='test')
                    # è‹¥é€‰æ‹©è¶…å‚æ•°è°ƒä¼˜æ–¹æ³•ï¼Œåˆ™æ ¹æ®é€‰æ‹©çš„æ–¹æ³•æœç´¢è¶…å‚æ•°å¹¶è®­ç»ƒæ¨¡å‹
                    else:
                        def create_model(hp):
                            hp_units = hp.Int('gru_units', min_value=32,
                                              max_value=512, step=8)
                            hp_layers = hp.Int('gru_layers', min_value=1,
                                               max_value=10, step=1)
                            gru = Sequential()
                            if hp_layers == 1:
                                gru.add(GRU(units=hp_units,
                                            activation=act_option,
                                            input_shape=(seq_length,
                                                         len(X_colums))))
                            else:
                                for i in range(hp_layers):
                                    if i == 0:
                                        gru.add(GRU(units=hp_units,
                                                    activation=act_option,
                                                    input_shape=(seq_length,
                                                                 len(X_colums)),
                                                    return_sequences=True))
                                    elif i == hp_layers-1:
                                        gru.add(GRU(units=hp_units,
                                                    activation=act_option))
                                    else:
                                        gru.add(GRU(units=hp_units,
                                                    dropout=dropout,
                                                    activation=act_option,
                                                    return_sequences=True))
                            gru.add(Dense(units=len(y_colums)))
                            gru.compile(optimizer=optimizer, loss='mse')
                            return gru
                        if hp_option == "ç½‘æ ¼æœç´¢":
                            tuner = kt.GridSearch(create_model,
                                                  objective='val_loss',
                                                  directory='Cache/hp tuning',
                                                  project_name='GRU GridSearch')
                        elif hp_option == "éšæœºæœç´¢":
                            tuner = kt.RandomSearch(create_model,
                                                    max_trials=epoch,
                                                    objective='val_loss',
                                                    directory='Cache/hp tuning',
                                                    project_name='GRU RandomSearch')
                        elif hp_option == "è´å¶æ–¯ä¼˜åŒ–":
                            tuner = kt.BayesianOptimization(create_model,
                                                            max_trials=epoch,
                                                            objective='val_loss',
                                                            directory='Cache/hp tuning',
                                                            project_name='GRU Bayesian')
                        elif hp_option == "Hyperband":
                            tuner = kt.Hyperband(create_model, max_epochs=epoch,
                                                 objective='val_loss',
                                                 directory='Cache/hp tuning',
                                                 project_name='GRU Hyperband')
                        early_stop = EarlyStopping(monitor='val_loss',
                                                   patience=10,
                                                   restore_best_weights=True)
                        tuner.search(X_train, y_train, validation_split=early,
                                     epochs=epoch, batch_size=batch,
                                     callbacks=[early_stop])
                        best_hps = tuner.get_best_hyperparameters()[0]
                        st.toast(best_hps.values)
                        # è·å–æ‹¥æœ‰æœ€ä½³è¶…å‚æ•°çš„æ¨¡å‹å¹¶ä¿å­˜
                        best_gru = tuner.get_best_models()[0]
                        best_gru.save('Cache/model/GRU.keras')
                        # åˆ†åˆ«åœ¨è®­ç»ƒé›†å’Œæµ‹è¯•é›†ä¸­é¢„æµ‹
                        y_train_pred = best_gru.predict(X_train)
                        y_test_pred = best_gru.predict(X_test)
                        # å°†æ•°æ®æ ¼å¼è½¬æ¢ä¸ºDataFrame
                        hist = pd.DataFrame(history.history)
                        y_train_pred = pd.DataFrame(y_train_pred)
                        y_test_pred = pd.DataFrame(y_test_pred)
                        y_train = pd.DataFrame(y_train, columns=y_colums)
                        y_test = pd.DataFrame(y_test, columns=y_colums)
                        # å°†æ•°æ®å‚¨å­˜åœ¨ç¼“å­˜ç›®å½•ä»¥ä¾¿äºåç»­ä½¿ç”¨å’Œè®¡ç®—
                        with pd.ExcelWriter('Cache/history/GRU results.xlsx') as writer:
                            hist.to_excel(writer, index=False,
                                          sheet_name='hist')
                            y_train_pred.to_excel(writer, index=False,
                                                  sheet_name='trainpred')
                            y_test_pred.to_excel(writer, index=False,
                                                 sheet_name='testpred')
                            y_train.to_excel(writer, index=False,
                                             sheet_name='train')
                            y_test.to_excel(writer, index=False,
                                            sheet_name='test')
        # å¸ƒå±€ï¼Œå°†è®­ç»ƒç»“æœå’Œæµ‹è¯•ç»“æœåˆ†æˆå·¦å³ä¸¤éƒ¨åˆ†æ˜¾ç¤º
        col_train, col_test = st.columns(2, gap="large")
        # å·¦éƒ¨åˆ†æ˜¾ç¤ºæµ‹è¯•æ•°æ®ä¸­çš„è¾“å…¥å˜é‡
        with col_train:
            hist_exists = check_sheet_exists(file_path='Cache/history/GRU results.xlsx',
                                             sheet_name='hist')
            trainpred_exists = check_sheet_exists(file_path='Cache/history/GRU results.xlsx',
                                                  sheet_name='trainpred')
            testpred_exists = check_sheet_exists(file_path='Cache/history/GRU results.xlsx',
                                                 sheet_name='testpred')
            train_exists = check_sheet_exists(file_path='Cache/history/GRU results.xlsx',
                                              sheet_name='train')
            test_exists = check_sheet_exists(file_path='Cache/history/GRU results.xlsx',
                                             sheet_name='test')
            # æ£€æŸ¥è®­ç»ƒå†å²è®°å½•æ˜¯å¦å­˜åœ¨
            if hist_exists:
                st.success("å·²æ£€æµ‹åˆ°è®­ç»ƒå†å²è®°å½•ï¼", icon="âœ…")
                # ç»˜åˆ¶è®­ç»ƒçš„Losså›¾
                hist = pd.read_excel('Cache/history/GRU results.xlsx',
                                     sheet_name='hist')
                st.caption('è®­ç»ƒè¿‡ç¨‹çš„Losså›¾ï¼š')
                st.line_chart(hist, x_label="Epoch", y_label="Loss")
                # æ£€æŸ¥è®­ç»ƒé›†çš„è¾“å‡ºå’Œé¢„æµ‹æ˜¯å¦å­˜åœ¨
                if trainpred_exists and train_exists:
                    # å¯¼å…¥æ‰€éœ€æ•°æ®
                    y_train_pred = pd.read_excel('Cache/history/GRU results.xlsx',
                                                 sheet_name='trainpred')
                    y_train = pd.read_excel('Cache/history/GRU results.xlsx',
                                            sheet_name='train')
                    y_colums = y_train.columns
                    # å°†DataFrameè½¬æ¢ä¸ºNumpyæ•°ç»„ä»¥ä¾¿äºåç»­åˆ‡ç‰‡
                    y_train_pred = np.array(y_train_pred)
                    y_train = np.array(y_train)
                    # æ¨¡å‹æ€§èƒ½è¯„ä¼°ï¼šè®­ç»ƒé›†ä¸­çš„R2
                    r2_train = []
                    for i in range(y_train.shape[1]):
                        r2_train_i = metrics.r2_score(y_train[:, i], y_train_pred[:, i])
                        r2_train.append(r2_train_i)
                    # ä»ç¼“å­˜ç›®å½•ä¸­è¯»å–æ ‡å‡†åŒ–å‰çš„æ•°æ®
                    data = pd.read_excel('Cache/imputed data.xlsx',
                                         sheet_name='filled')
                    # è½¬æ¢æ—¶é—´æ ¼å¼
                    data['æ—¶é—´'] = pd.to_datetime(data['æ—¶é—´'],
                                                format='%Y-%m-%d %H:%M:%S')
                    # æå–æ—¶é—´ä¿¡æ¯å¹¶å°†æ—¶é—´ä¿¡æ¯è½¬æ¢ä¸ºç´¢å¼•
                    data_index = data['æ—¶é—´']
                    data.index = data_index
                    # åˆ é™¤å¤šä½™çš„æ—¶é—´åˆ—å¹¶æå–è¾“å‡ºå˜é‡
                    data.drop(columns=['æ—¶é—´'], axis=1, inplace=True)
                    y_data = data[y_colums]
                    # ä»ç¼“å­˜ç›®å½•ä¸­åŠ è½½æ ‡å‡†åŒ–æ–¹æ³•
                    with open('Cache/scaler.pkl', 'rb') as f:
                        scaler = pickle.load(f)
                    # æ‹Ÿåˆæ ‡å‡†åŒ–æ–¹æ³•ä¸ºåæ ‡å‡†åŒ–åšå‡†å¤‡
                    y_scaled = scaler.fit_transform(y_data)
                    # å¯¹è¾“å‡ºå˜é‡çš„çœŸå®å€¼å’Œé¢„æµ‹å€¼è¿›è¡Œåæ ‡å‡†åŒ–
                    y_train = scaler.inverse_transform(y_train)
                    y_train_pred = scaler.inverse_transform(y_train_pred)
                    # æ¨¡å‹æ€§èƒ½è¯„ä¼°ï¼šè®­ç»ƒé›†ä¸­çš„MAE
                    mae_train = []
                    for i in range(y_train.shape[1]):
                        mae_train_i = metrics.mean_absolute_error(y_train[:, i], y_train_pred[:, i])
                        mae_train.append(mae_train_i)
                    # æ¨¡å‹æ€§èƒ½è¯„ä¼°ï¼šè®­ç»ƒé›†ä¸­çš„MSE    
                    mse_train = []
                    for i in range(y_train.shape[1]):
                        mse_train_i = metrics.mean_squared_error(y_train[:, i], y_train_pred[:, i])
                        mse_train.append(mse_train_i)
                    # å°†æ‰€æœ‰ç»“æœè½¬æ¢ä¸ºDataFrameæ ¼å¼ä»¥ä¾¿äºå‰ç«¯å±•ç¤º
                    r2_train = pd.DataFrame(r2_train, columns=['R2'])
                    mae_train = pd.DataFrame(mae_train, columns=['MAE'])
                    mse_train = pd.DataFrame(mse_train, columns=['MSE'])
                    # æ±‡æ€»ç»“æœ
                    train_result = pd.concat([r2_train, mae_train,
                                              mse_train], axis=1)
                    train_result.index = y_colums
                    train_result = train_result.T
                    # åœ¨å‰ç«¯æ˜¾ç¤ºç»“æœ
                    st.caption('æ¨¡å‹çš„è®­ç»ƒç»“æœå¦‚ä¸‹æ‰€ç¤ºï¼š')
                    st.dataframe(train_result, use_container_width=True)
                # è‹¥è®­ç»ƒé›†çš„è¾“å‡ºå’Œé¢„æµ‹ä¸å­˜åœ¨ï¼Œåˆ™æç¤º
                else:
                    st.caption('æ¨¡å‹çš„è®­ç»ƒç»“æœå¦‚ä¸‹æ‰€ç¤ºï¼š')
                    st.info('æœªæ£€æµ‹åˆ°è®­ç»ƒç»“æœï¼', icon="â„¹ï¸")
            # è‹¥è®­ç»ƒå†å²è®°å½•ä¸å­˜åœ¨ï¼Œåˆ™æç¤º
            else:
                st.caption('è®­ç»ƒè¿‡ç¨‹çš„Losså›¾ï¼š')
                st.info('æœªæ£€æµ‹åˆ°è®­ç»ƒå†å²ï¼', icon="â„¹ï¸")
                st.caption('æ¨¡å‹çš„è®­ç»ƒç»“æœå¦‚ä¸‹æ‰€ç¤ºï¼š')
                st.info('è¯·å…ˆè®­ç»ƒæ¨¡å‹ï¼', icon="â„¹ï¸")
        # å³éƒ¨åˆ†æ˜¾ç¤ºæµ‹è¯•æ•°æ®ä¸­çš„è¾“å‡ºå˜é‡
        with col_test:
            if testpred_exists and test_exists:
                # ç»˜åˆ¶è®­ç»ƒçš„Losså›¾
                st.success("å·²æ£€æµ‹åˆ°æ¨¡å‹æµ‹è¯•ç»“æœï¼", icon="âœ…")
                st.caption('æµ‹è¯•è¿‡ç¨‹ä¸­é¢„æµ‹å€¼ä¸çœŸå®å€¼çš„å¯¹æ¯”ï¼š')
                y_test_pred = pd.read_excel('Cache/history/GRU results.xlsx',
                                            sheet_name='testpred')
                y_test = pd.read_excel('Cache/history/GRU results.xlsx',
                                       sheet_name='test')
                y_colums = y_test.columns
                y_test_pred = np.array(y_test_pred)
                y_test = np.array(y_test)
                data_dict = {}
                column_names = []
                for i in range(len(y_colums)):
                    true_name = f"çœŸå®å€¼_{i}"
                    pred_name = f"é¢„æµ‹å€¼_{i}"
                    column_names.extend([true_name, pred_name])
                    data_dict[true_name] = y_test[:, i]
                    data_dict[pred_name] = y_test_pred[:, i]
                    chart_data = pd.DataFrame(data_dict)
                st.line_chart(chart_data, x_label="æ—¶é—´", y_label="æ ‡å‡†åŒ–å€¼")
                # æ¨¡å‹æ€§èƒ½è¯„ä¼°ï¼šæµ‹è¯•é›†ä¸­çš„R2
                r2_test = []
                for i in range(y_test.shape[1]):
                    r2_test_i = metrics.r2_score(y_test[:, i], y_test_pred[:, i])
                    r2_test.append(r2_test_i)
                # ä»ç¼“å­˜ç›®å½•ä¸­è¯»å–æ ‡å‡†åŒ–å‰çš„æ•°æ®
                data = pd.read_excel('Cache/imputed data.xlsx',
                                     sheet_name='filled')
                # è½¬æ¢æ—¶é—´æ ¼å¼
                data['æ—¶é—´'] = pd.to_datetime(data['æ—¶é—´'],
                                            format='%Y-%m-%d %H:%M:%S')
                # æå–æ—¶é—´ä¿¡æ¯å¹¶å°†æ—¶é—´ä¿¡æ¯è½¬æ¢ä¸ºç´¢å¼•
                data_index = data['æ—¶é—´']
                data.index = data_index
                # åˆ é™¤å¤šä½™çš„æ—¶é—´åˆ—å¹¶æå–è¾“å‡ºå˜é‡
                data.drop(columns=['æ—¶é—´'], axis=1, inplace=True)
                y_data = data[y_colums]
                # ä»ç¼“å­˜ç›®å½•ä¸­åŠ è½½æ ‡å‡†åŒ–æ–¹æ³•
                with open('Cache/scaler.pkl', 'rb') as f:
                    scaler = pickle.load(f)
                # æ‹Ÿåˆæ ‡å‡†åŒ–æ–¹æ³•ä¸ºåæ ‡å‡†åŒ–åšå‡†å¤‡
                y_scaled = scaler.fit_transform(y_data)
                # å¯¹è¾“å‡ºå˜é‡çš„çœŸå®å€¼å’Œé¢„æµ‹å€¼è¿›è¡Œåæ ‡å‡†åŒ–
                y_test = scaler.inverse_transform(y_test)
                y_test_pred = scaler.inverse_transform(y_test_pred)
                # æ¨¡å‹æ€§èƒ½è¯„ä¼°ï¼šæµ‹è¯•é›†ä¸­çš„MAE
                mae_test = []
                for i in range(y_test.shape[1]):
                    mae_test_i = metrics.mean_absolute_error(y_test[:, i],
                                                             y_test_pred[:, i])
                    mae_test.append(mae_test_i)
                # æ¨¡å‹æ€§èƒ½è¯„ä¼°ï¼šæµ‹è¯•é›†ä¸­çš„MSE
                mse_test = []
                for i in range(y_test.shape[1]):
                    mse_test_i = metrics.mean_squared_error(y_test[:, i],
                                                            y_test_pred[:, i])
                    mse_test.append(mse_test_i)
                # å°†æ‰€æœ‰ç»“æœè½¬æ¢ä¸ºDataFrameæ ¼å¼ä»¥ä¾¿äºå‰ç«¯å±•ç¤º
                r2_test = pd.DataFrame(r2_test, columns=['R2'])
                mae_test = pd.DataFrame(mae_test, columns=['MAE'])
                mse_test = pd.DataFrame(mse_test, columns=['MSE'])
                # æ±‡æ€»ç»“æœ
                test_result = pd.concat([r2_test, mae_test,
                                         mse_test], axis=1)
                test_result.index = y_colums
                test_result = test_result.T
                # åœ¨å‰ç«¯æ˜¾ç¤ºç»“æœ
                st.caption('æ¨¡å‹çš„è®­ç»ƒç»“æœå¦‚ä¸‹æ‰€ç¤ºï¼š')
                st.dataframe(test_result, use_container_width=True)
            # è‹¥æµ‹è¯•ç»“æœè®°å½•ä¸å­˜åœ¨ï¼Œåˆ™æç¤º
            else:
                st.caption('æµ‹è¯•è¿‡ç¨‹ä¸­é¢„æµ‹å€¼ä¸çœŸå®å€¼çš„å¯¹æ¯”ï¼š')
                st.info('æœªæ£€æµ‹åˆ°æµ‹è¯•ç»“æœï¼', icon="â„¹ï¸")
                st.caption('æ¨¡å‹çš„æµ‹è¯•ç»“æœå¦‚ä¸‹æ‰€ç¤ºï¼š')
                st.info('è¯·å…ˆè®­ç»ƒæ¨¡å‹ï¼', icon="â„¹ï¸")
# ç¬¬ä¸‰éƒ¨åˆ†çš„ç¬¬å››é¡µï¼šSeq2Seqæ¨¡å‹
def page_34():
    with st.container(border=True):
        # è®¾ç½®å­æ ‡é¢˜
        st.subheader('*åºåˆ—åˆ°åºåˆ—æ¨¡å‹ï¼ˆSeq2Seqï¼‰*')
        with st.spinner('æ£€æµ‹æ•°æ®ä¸­ï¼Œè¯·ç¨å...'):
            # æ£€æŸ¥æ•°æ®æ˜¯å¦å­˜åœ¨
            X_train_exists = check_sheet_exists(file_path='Cache/X train data.xlsx',
                                                sheet_name='X')
            y_train_exists = check_sheet_exists(file_path='Cache/y train data.xlsx',
                                                sheet_name='y')
            X_test_exists = check_sheet_exists(file_path='Cache/X test data.xlsx',
                                               sheet_name='X')
            y_test_exists = check_sheet_exists(file_path='Cache/y test data.xlsx',
                                               sheet_name='y')
            if X_train_exists and X_test_exists and y_train_exists and y_test_exists:
                # æç¤ºæˆåŠŸæ£€æµ‹
                st.success("å·²æ£€æµ‹åˆ°åˆ’åˆ†çš„è®­ç»ƒé›†å’Œæµ‹è¯•é›†ï¼è¯·æ‚¨æŒ‰ç…§æµç¨‹å®Œæˆè®­ç»ƒï¼", icon="âœ…")
                # è¦æ±‚ç”¨æˆ·é€‰æ‹©è¶…å‚æ•°è°ƒä¼˜æ–¹æ³•
                hp_option = st.selectbox("**è¯·é€‰æ‹©è¶…å‚æ•°è°ƒä¼˜æ–¹æ³•ï¼š**",
                                         ("ç½‘æ ¼æœç´¢", "éšæœºæœç´¢", "è´å¶æ–¯ä¼˜åŒ–",
                                          "Hyperband", "äººä¸ºæŒ‡å®š"), index=4)
                # è¦æ±‚ç”¨æˆ·é€‰æ‹©åŸºæœ¬å•å…ƒ
                hp_rnn = st.selectbox("**è¯·é€‰æ‹©åŸºæœ¬å•å…ƒï¼š**",
                                      ("LSTM", "GRU"), index=1)
                # å¦‚æœé€‰æ‹©äººä¸ºæŒ‡å®šï¼Œåˆ™æ¿€æ´»æ‰€æœ‰åŠŸèƒ½
                if hp_option == "äººä¸ºæŒ‡å®š":
                    # è®¾ç½®æäº¤è¡¨å•
                    with st.form('seq_form'):
                        # è¦æ±‚ç”¨æˆ·é€‰æ‹©æ—¶é—´æ­¥é•¿
                        seq_length = st.number_input("**æ—¶é—´æ­¥é•¿ï¼š**", value=7,
                                                     min_value=1)
                        # è¦æ±‚ç”¨æˆ·ä¸ºæå‰ç»ˆæ­¢æ³•æŒ‡å®šéªŒè¯æ¯”ä¾‹
                        early = st.number_input("**æå‰ç»ˆæ­¢æ³•éªŒè¯æ¯”ä¾‹ï¼š**",
                                                value=0.2, min_value=0.1,
                                                max_value=0.5)
                        # è¦æ±‚ç”¨æˆ·é€‰æ‹©ä¼˜åŒ–å™¨
                        optimizer = st.selectbox("**ä¼˜åŒ–å™¨ï¼š**",
                                                 ("adam", "sgd", "rmsprop",
                                                  "adadelta"))
                        # è¦æ±‚ç”¨æˆ·æŒ‡å®šæ‰¹æ¬¡å¤§å°
                        batch = st.number_input("**æ‰¹æ¬¡å¤§å°ï¼š**",
                                                value=32, min_value=8)
                        # è¦æ±‚ç”¨æˆ·æŒ‡å®šæœ€å¤§è¿­ä»£æ¬¡æ•°
                        epoch = st.number_input("**æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼š**",
                                                value=1000, min_value=100)
                        # è‹¥è¶…å‚æ•°è°ƒä¼˜æ–¹æ³•é€‰æ‹©äººå·¥æŒ‡å®šåˆ™è¦æ±‚ç”¨æˆ·é€‰æ‹©GRUçš„èŠ‚ç‚¹æ•°å’Œå±‚æ•°
                        encoder = st.number_input("**ç¼–ç å™¨å±‚æ•°ï¼š**", value=1,
                                                  min_value=1)
                        decoder = st.number_input("**è§£ç å™¨å±‚æ•°ï¼š**", value=1,
                                                  min_value=1)
                        units = st.number_input("**èŠ‚ç‚¹æ•°ï¼š**", value=8,
                                                min_value=1)
                        # è®¾ç½®æäº¤æŒ‰é’®
                        submitted = st.form_submit_button('ç¡®å®šå¹¶è®­ç»ƒ')
                # å¦‚æœä½¿ç”¨æœç´¢æ–¹æ³•ï¼Œåˆ™ç¦ç”¨ä¸€éƒ¨åˆ†åŠŸèƒ½
                else:
                    # è®¾ç½®æäº¤è¡¨å•
                    with st.form('seq_form'):
                        seq_length = st.number_input("**æ—¶é—´æ­¥é•¿ï¼š**", value=7,
                                                     min_value=1)
                        early = st.number_input("**æå‰ä¸­æ­¢æ³•éªŒè¯æ¯”ä¾‹ï¼š**",
                                                value=0.2, min_value=0.1,
                                                max_value=0.5)
                        optimizer = st.selectbox("**ä¼˜åŒ–å™¨ï¼š**",
                                                 ("adam", "sgd", "rmsprop",
                                                  "adadelta"))
                        batch = st.number_input("**æ‰¹æ¬¡å¤§å°ï¼š**",
                                                value=32, min_value=8)
                        epoch = st.number_input("**æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼š**",
                                                value=1000, min_value=100)
                        encoder = st.number_input("**ç¼–ç å™¨å±‚æ•°ï¼š**", value=1,
                                                  min_value=1, disabled=True)
                        decoder = st.number_input("**è§£ç å™¨å±‚æ•°ï¼š**", value=1,
                                                  min_value=1, disabled=True)
                        units = st.number_input("**èŠ‚ç‚¹æ•°ï¼š**", value=8,
                                                min_value=1, disabled=True)
                        submitted = st.form_submit_button('ç¡®å®šå¹¶è®­ç»ƒ')
            # è‹¥æœªæ£€æµ‹åˆ°æ•°æ®ï¼Œåˆ™ç¦ç”¨æ‰€æœ‰é€‰é¡¹å¹¶æç¤ºä¸Šä¼ å¤„ç†
            else:
                st.info('è¯·å®Œæˆæ•°æ®å¤„ç†ï¼', icon="â„¹ï¸")
                hp_option = st.selectbox("**è¯·é€‰æ‹©è¶…å‚æ•°è°ƒä¼˜æ–¹æ³•ï¼š**",
                                         ("ç½‘æ ¼æœç´¢", "éšæœºæœç´¢", "è´å¶æ–¯ä¼˜åŒ–",
                                          "Hyperband", "äººä¸ºæŒ‡å®š"), index=4,
                                         disabled=True)
                with st.form('seq_form'):
                    seq_length = st.number_input("**æ—¶é—´æ­¥é•¿ï¼š**", value=7,
                                                 min_value=1, disabled=True)
                    early = st.number_input("**æå‰ä¸­æ­¢æ³•éªŒè¯æ¯”ä¾‹ï¼š**",
                                            value=0.2, min_value=0.1,
                                            max_value=0.5, disabled=True)
                    optimizer = st.selectbox("**ä¼˜åŒ–å™¨ï¼š**",
                                             ("adam", "sgd", "rmsprop",
                                              "adadelta"), disabled=True)
                    batch = st.number_input("**æ‰¹æ¬¡å¤§å°ï¼š**", value=32,
                                            min_value=8, disabled=True)
                    epoch = st.number_input("**æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼š**",
                                            value=1000, min_value=100,
                                            disabled=True)
                    encoder = st.number_input("**ç¼–ç å™¨å±‚æ•°ï¼š**", value=1,
                                              min_value=1, disabled=True)
                    decoder = st.number_input("**è§£ç å™¨å±‚æ•°ï¼š**", value=1,
                                              min_value=1, disabled=True)
                    units = st.number_input("**èŠ‚ç‚¹æ•°ï¼š**", value=8,
                                            min_value=1, disabled=True)
                    submitted = st.form_submit_button('ç¡®å®šå¹¶è®­ç»ƒ', disabled=True)
    with st.container(border=True):
        # è®¾ç½®å­æ ‡é¢˜
        st.subheader('è®­ç»ƒç»“æœ')
        if submitted:
            with st.spinner('è®­ç»ƒä¸­ï¼Œè¯·ç¨å...'):
                # ä¿å­˜è®¾ç½®çš„æ—¶é—´æ­¥é•¿ä»¥ä¾¿äºåç»­å°†æ–°æ•°æ®è½¬æ¢ä¸ºä¸‰ä½å¼ é‡æ ¼å¼
                seq_frame = pd.DataFrame({'seq_length': [seq_length]})
                seq_frame.to_excel('Cache/sequence length.xlsx', index=False)
                # æ£€æŸ¥è®­ç»ƒæ•°æ®é›†ä¸­çš„è¾“å…¥å˜é‡æ•°æ®å’Œè¾“å‡ºå˜é‡æ•°æ®æ˜¯å¦å­˜åœ¨
                X_train_exists = check_sheet_exists(file_path='Cache/X train data.xlsx',
                                                    sheet_name='X')
                y_train_exists = check_sheet_exists(file_path='Cache/y train data.xlsx',
                                                    sheet_name='y')
                X_test_exists = check_sheet_exists(file_path='Cache/X test data.xlsx',
                                                   sheet_name='X')
                y_test_exists = check_sheet_exists(file_path='Cache/y test data.xlsx',
                                                   sheet_name='y')
                if X_train_exists and X_test_exists and y_train_exists and y_test_exists:
                    # ä»ç¼“å­˜ç›®å½•ä¸­è¯»å–è¾“å…¥æ•°æ®å¹¶è½¬æ¢æ ¼å¼ä»¥ä¾¿äºæ“ä½œ
                    X_train = pd.read_excel('Cache/X train data.xlsx',
                                            sheet_name='X')
                    X_test = pd.read_excel('Cache/X test data.xlsx',
                                           sheet_name='X')
                    X_train['æ—¶é—´'] = pd.to_datetime(X_train['æ—¶é—´'],
                                                   format='%Y-%m-%d %H:%M:%S')
                    X_test['æ—¶é—´'] = pd.to_datetime(X_test['æ—¶é—´'],
                                                  format='%Y-%m-%d %H:%M:%S')
                    X_train_index = X_train['æ—¶é—´']
                    X_test_index = X_test['æ—¶é—´']
                    X_train.index = X_train_index
                    X_test.index = X_test_index
                    X_train.drop(columns=['æ—¶é—´'], axis=1, inplace=True)
                    X_test.drop(columns=['æ—¶é—´'], axis=1, inplace=True)
                    X_colums = X_train.columns
                    # ä»ç¼“å­˜ç›®å½•ä¸­è¯»å–è¾“å‡ºæ•°æ®å¹¶è½¬æ¢æ ¼å¼ä»¥ä¾¿äºæ“ä½œ
                    y_train = pd.read_excel('Cache/y train data.xlsx',
                                            sheet_name='y')
                    y_test = pd.read_excel('Cache/y test data.xlsx',
                                           sheet_name='y')
                    y_train['æ—¶é—´'] = pd.to_datetime(y_train['æ—¶é—´'],
                                                   format='%Y-%m-%d %H:%M:%S')
                    y_test['æ—¶é—´'] = pd.to_datetime(y_test['æ—¶é—´'],
                                                  format='%Y-%m-%d %H:%M:%S')
                    y_train_index = y_train['æ—¶é—´']
                    y_test_index = y_test['æ—¶é—´']
                    y_train.index = y_train_index
                    y_test.index = y_test_index
                    y_train.drop(columns=['æ—¶é—´'], axis=1, inplace=True)
                    y_test.drop(columns=['æ—¶é—´'], axis=1, inplace=True)
                    y_colums = y_train.columns
                    # å°†DataFrameè½¬æ¢ä¸ºNumpyæ•°ç»„æ ¼å¼ä»¥ä¾¿äºåç»­æ•°æ®å½¢å¼è½¬æ¢
                    X_train = np.array(X_train)
                    y_train = np.array(y_train)
                    X_test = np.array(X_test)
                    y_test = np.array(y_test)
                    # å°†æ•°æ®è½¬æ¢ä¸ºåºåˆ—æ ¼å¼
                    X_train, y_train = create_sequences(X_train, y_train,
                                                        seq_length)
                    X_test, y_test = create_sequences(X_test, y_test,
                                                      seq_length)
                    # è‹¥é€‰æ‹©äººä¸ºæŒ‡å®šè¶…å‚æ•°ï¼Œåˆ™æ ¹æ®æŒ‡å®šçš„è¶…å‚æ•°è®­ç»ƒæ¨¡å‹
                    if hp_option == "äººä¸ºæŒ‡å®š":
                        # è‹¥é€‰æ‹©LSTMä¸ºåŸºæœ¬å•å…ƒ
                        if hp_rnn == "LSTM":
                            encoder_input = Input(shape=(seq_length, len(X_colums)))
                            encoder_lstm = encoder_input
                            encoder_states = []
                            for i in range(encoder):
                                if i < encoder - 1:
                                    encoder_lstm, state_h, state_c = LSTM(units, return_sequences=True, return_state=True)(encoder_lstm)
                                    encoder_states.extend([state_h, state_c])
                                else:
                                    encoder_lstm, state_h, state_c = LSTM(units, return_state=True)(encoder_lstm)
                                    encoder_states.extend([state_h, state_c])
                            decoder_input = Input(shape=(1, len(y_colums)))
                            decoder_reshaped = Reshape((1, len(y_colums)))(decoder_input)
                            decoder_lstm = decoder_reshaped
                            for i in range(decoder):
                                if i < decoder - 1:
                                    decoder_lstm, state_h, state_c = LSTM(units, return_sequences=True, return_state=True)(decoder_lstm, initial_state=encoder_states[-2:] if i == 0 else None)
                                    encoder_states[-2:] = [state_h, state_c]
                                else:
                                    decoder_lstm, state_h, state_c = LSTM(units, return_sequences=True, return_state=True)(decoder_lstm, initial_state=encoder_states[-2:] if i == 0 else None)
                                    encoder_states[-2:] = [state_h, state_c]
                            decoder_output = Dense(len(y_colums))(decoder_lstm)
                        # å¦åˆ™é»˜è®¤GRUä¸ºåŸºæœ¬å•å…ƒ
                        else:
                            encoder_input = Input(shape=(seq_length, len(X_colums)))
                            encoder_gru = encoder_input
                            encoder_states = []
                            for i in range(encoder):
                                if i < encoder - 1:
                                    encoder_gru, state = GRU(units, return_sequences=True, return_state=True)(encoder_gru)
                                else:
                                    encoder_gru, state = GRU(units, return_state=True)(encoder_gru)
                                encoder_states.append(state)
                            decoder_input = Input(shape=(1, len(y_colums)))
                            decoder_reshaped = Reshape((1, len(y_colums)))(decoder_input)
                            decoder_gru = decoder_reshaped
                            for i in range(decoder):
                                if i < decoder - 1:
                                    decoder_gru, state = GRU(units, return_sequences=True, return_state=True)(decoder_gru, initial_state=encoder_states[-1] if i == 0 else None)
                                else:
                                    decoder_gru, state = GRU(units, return_sequences=True, return_state=True)(decoder_gru, initial_state=encoder_states[-1] if i == 0 else None)
                            decoder_output = Dense(len(y_colums))(decoder_gru)
                        # å»ºç«‹Seq2Seqæ¨¡å‹
                        seq = Model(inputs=[encoder_input, decoder_input], outputs=decoder_output)
                        early_stop = EarlyStopping(monitor='val_loss',
                                                   patience=10,
                                                   restore_best_weights=True)
                        seq.compile(optimizer=optimizer, loss='mse')
                        # å°†äºŒç»´è¾“å‡ºå˜é‡è½¬æ¢ä¸ºä¸‰ç»´
                        train_y = y_train.reshape(-1, 1, len(y_colums))
                        test_y = y_test.reshape(-1, 1, len(y_colums))
                        history = seq.fit([X_train, np.zeros_like(train_y)],
                                          train_y, epochs=epoch,
                                          batch_size=batch,
                                          validation_split=early,
                                          callbacks=[early_stop])
                        # å‚¨å­˜æ¨¡å‹
                        seq.save('Cache/model/Seq2Seq.keras')
                        # åˆ†åˆ«åœ¨è®­ç»ƒé›†å’Œæµ‹è¯•é›†ä¸­é¢„æµ‹
                        y_train_pred = seq.predict([X_train,
                                                    np.zeros_like(train_y)])
                        y_test_pred = seq.predict([X_test,
                                                   np.zeros_like(test_y)])
                        # å°†é¢„æµ‹ç»“æœè½¬æ¢ä¸ºäºŒç»´ä»¥ä¾¿äºåç»­è®¡ç®—
                        y_train_pred = y_train_pred[:, 0, :]
                        y_test_pred = y_test_pred[:, 0, :]
                        # å°†æ•°æ®æ ¼å¼è½¬æ¢ä¸ºDataFrame
                        hist = pd.DataFrame(history.history)
                        y_train_pred = pd.DataFrame(y_train_pred)
                        y_test_pred = pd.DataFrame(y_test_pred)
                        y_train = pd.DataFrame(y_train, columns=y_colums)
                        y_test = pd.DataFrame(y_test, columns=y_colums)
                        # å°†æ•°æ®å‚¨å­˜åœ¨ç¼“å­˜ç›®å½•ä»¥ä¾¿äºåç»­ä½¿ç”¨å’Œè®¡ç®—
                        with pd.ExcelWriter('Cache/history/Seq2Seq results.xlsx') as writer:
                            hist.to_excel(writer, index=False,
                                          sheet_name='hist')
                            y_train_pred.to_excel(writer, index=False,
                                                  sheet_name='trainpred')
                            y_test_pred.to_excel(writer, index=False,
                                                 sheet_name='testpred')
                            y_train.to_excel(writer, index=False,
                                             sheet_name='train')
                            y_test.to_excel(writer, index=False,
                                            sheet_name='test')
                    # è‹¥é€‰æ‹©è¶…å‚æ•°è°ƒä¼˜æ–¹æ³•ï¼Œåˆ™æ ¹æ®é€‰æ‹©çš„æ–¹æ³•æœç´¢è¶…å‚æ•°å¹¶è®­ç»ƒæ¨¡å‹
                    else:
                        # è‹¥é€‰æ‹©LSTMæ¨¡å‹åˆ™å»ºç«‹
                        if hp_rnn == "LSTM":
                            def create_model(hp):
                                hp_units = hp.Int('units', min_value=32,
                                                  max_value=512, step=8)
                                hp_layers_1 = hp.Int('encoder_layers',
                                                     min_value=1, max_value=10,
                                                     step=1)
                                hp_layers_2 = hp.Int('decoder_layers',
                                                     min_value=1, max_value=10,
                                                     step=1)
                                encoder_input = Input(shape=(seq_length, len(X_colums)))
                                encoder_lstm = encoder_input
                                encoder_states = []
                                for i in range(hp_layers_1):
                                    if i < encoder - 1:
                                        encoder_lstm, state_h, state_c = LSTM(hp_units, return_sequences=True, return_state=True)(encoder_lstm)
                                        encoder_states.extend([state_h, state_c])
                                    else:
                                        encoder_lstm, state_h, state_c = LSTM(hp_units, return_state=True)(encoder_lstm)
                                        encoder_states.extend([state_h, state_c])
                                decoder_input = Input(shape=(1, len(y_colums)))
                                decoder_reshaped = Reshape((1, len(y_colums)))(decoder_input)
                                decoder_lstm = decoder_reshaped
                                for i in range(hp_layers_2):
                                    if i < decoder - 1:
                                        decoder_lstm, state_h, state_c = LSTM(hp_units, return_sequences=True, return_state=True)(decoder_lstm, initial_state=encoder_states[-2:] if i == 0 else None)
                                        encoder_states[-2:] = [state_h, state_c]
                                    else:
                                        decoder_lstm, state_h, state_c = LSTM(hp_units, return_sequences=True, return_state=True)(decoder_lstm, initial_state=encoder_states[-2:] if i == 0 else None)
                                        encoder_states[-2:] = [state_h, state_c]
                                decoder_output = Dense(len(y_colums))(decoder_lstm)
                                seq = Model(inputs=[encoder_input, decoder_input], outputs=decoder_output)
                                seq.compile(optimizer=optimizer, loss='mse')
                                return seq
                        # å¦åˆ™å»ºç«‹GRUæ¨¡å‹
                        else:
                            def create_model(hp):
                                hp_units = hp.Int('units', min_value=32,
                                                  max_value=512, step=8)
                                hp_layers_1 = hp.Int('encoder_layers',
                                                     min_value=1, max_value=10,
                                                     step=1)
                                hp_layers_2 = hp.Int('decoder_layers',
                                                     min_value=1, max_value=10,
                                                     step=1)
                                encoder_input = Input(shape=(seq_length, len(X_colums)))
                                encoder_gru = encoder_input
                                encoder_states = []
                                for i in range(hp_layers_1):
                                    if i < hp_layers_1 - 1:
                                        encoder_gru, state = GRU(hp_units, return_sequences=True, return_state=True)(encoder_gru)
                                    else:
                                        encoder_gru, state = GRU(hp_units, return_state=True)(encoder_gru)
                                    encoder_states.append(state)
                                decoder_input = Input(shape=(1, len(y_colums)))
                                decoder_reshaped = Reshape((1, len(y_colums)))(decoder_input)
                                decoder_gru = decoder_reshaped
                                for i in range(hp_layers_2):
                                    if i < hp_layers_2 - 1:
                                        decoder_gru, state = GRU(hp_units, return_sequences=True, return_state=True)(decoder_gru, initial_state=encoder_states[-1] if i == 0 else None)
                                    else:
                                        decoder_gru, state = GRU(hp_units, return_sequences=True, return_state=True)(decoder_gru, initial_state=encoder_states[-1] if i == 0 else None)
                                decoder_output = Dense(len(y_colums))(decoder_gru)
                                seq = Model(inputs=[encoder_input, decoder_input], outputs=decoder_output)
                                seq.compile(optimizer=optimizer, loss='mse')
                                return seq
                            if hp_option == "ç½‘æ ¼æœç´¢":
                                tuner = kt.GridSearch(create_model,
                                                      objective='val_loss',
                                                      directory='Cache/hp tuning',
                                                      project_name='Seq2Seq GridSearch')
                            elif hp_option == "éšæœºæœç´¢":
                                tuner = kt.RandomSearch(create_model,
                                                        max_trials=epoch,
                                                        objective='val_loss',
                                                        directory='Cache/hp tuning',
                                                        project_name='Seq2Seq RandomSearch')
                            elif hp_option == "è´å¶æ–¯ä¼˜åŒ–":
                                tuner = kt.BayesianOptimization(create_model,
                                                                max_trials=epoch,
                                                                objective='val_loss',
                                                                directory='Cache/hp tuning',
                                                                project_name='Seq2Seq Bayesian')
                            elif hp_option == "Hyperband":
                                tuner = kt.Hyperband(create_model,
                                                     max_epochs=epoch,
                                                     objective='val_loss',
                                                     directory='Cache/hp tuning',
                                                     project_name='Seq2Seq Hyperband')
                            early_stop = EarlyStopping(monitor='val_loss',
                                                       patience=10,
                                                       restore_best_weights=True)
                            # å°†äºŒç»´è¾“å‡ºå˜é‡è½¬æ¢ä¸ºä¸‰ç»´
                            train_y = y_train.reshape(-1, 1, len(y_colums))
                            test_y = y_test.reshape(-1, 1, len(y_colums))
                            tuner.search([X_train, np.zeros_like(train_y)],
                                         train_y, validation_split=early,
                                         epochs=epoch, batch_size=batch,
                                         callbacks=[early_stop])
                            best_hps = tuner.get_best_hyperparameters()[0]
                            st.toast(best_hps.values)
                            # è·å–æ‹¥æœ‰æœ€ä½³è¶…å‚æ•°çš„æ¨¡å‹å¹¶ä¿å­˜
                            best_seq = tuner.get_best_models()[0]
                            best_seq.save('Cache/model/Seq2Seq.keras')
                            # åˆ†åˆ«åœ¨è®­ç»ƒé›†å’Œæµ‹è¯•é›†ä¸­é¢„æµ‹
                            y_train_pred = best_seq.predict([X_train, np.zeros_like(train_y)])
                            y_test_pred = best_seq.predict([X_test, np.zeros_like(test_y)])
                            # å°†é¢„æµ‹ç»“æœè½¬æ¢ä¸ºäºŒç»´ä»¥ä¾¿äºåç»­è®¡ç®—
                            y_train_pred = y_train_pred[:, 0, :]
                            y_test_pred = y_test_pred[:, 0, :]
                            # å°†æ•°æ®æ ¼å¼è½¬æ¢ä¸ºDataFrame
                            hist = pd.DataFrame(history.history)
                            y_train_pred = pd.DataFrame(y_train_pred)
                            y_test_pred = pd.DataFrame(y_test_pred)
                            y_train = pd.DataFrame(y_train, columns=y_colums)
                            y_test = pd.DataFrame(y_test, columns=y_colums)
                            # å°†æ•°æ®å‚¨å­˜åœ¨ç¼“å­˜ç›®å½•ä»¥ä¾¿äºåç»­ä½¿ç”¨å’Œè®¡ç®—
                            with pd.ExcelWriter('Cache/history/Seq2Seq results.xlsx') as writer:
                                hist.to_excel(writer, index=False,
                                              sheet_name='hist')
                                y_train_pred.to_excel(writer, index=False,
                                                      sheet_name='trainpred')
                                y_test_pred.to_excel(writer, index=False,
                                                     sheet_name='testpred')
                                y_train.to_excel(writer, index=False,
                                                 sheet_name='train')
                                y_test.to_excel(writer, index=False,
                                                sheet_name='test')
        # å¸ƒå±€ï¼Œå°†è®­ç»ƒç»“æœå’Œæµ‹è¯•ç»“æœåˆ†æˆå·¦å³ä¸¤éƒ¨åˆ†æ˜¾ç¤º
        col_train, col_test = st.columns(2, gap="large")
        # å·¦éƒ¨åˆ†æ˜¾ç¤ºæµ‹è¯•æ•°æ®ä¸­çš„è¾“å…¥å˜é‡
        with col_train:
            hist_exists = check_sheet_exists(file_path='Cache/history/Seq2Seq results.xlsx',
                                             sheet_name='hist')
            trainpred_exists = check_sheet_exists(file_path='Cache/history/Seq2Seq results.xlsx',
                                                  sheet_name='trainpred')
            testpred_exists = check_sheet_exists(file_path='Cache/history/Seq2Seq results.xlsx',
                                                 sheet_name='testpred')
            train_exists = check_sheet_exists(file_path='Cache/history/Seq2Seq results.xlsx',
                                              sheet_name='train')
            test_exists = check_sheet_exists(file_path='Cache/history/Seq2Seq results.xlsx',
                                             sheet_name='test')
            # æ£€æŸ¥è®­ç»ƒå†å²è®°å½•æ˜¯å¦å­˜åœ¨
            if hist_exists:
                st.success("å·²æ£€æµ‹åˆ°è®­ç»ƒå†å²è®°å½•ï¼", icon="âœ…")
                # ç»˜åˆ¶è®­ç»ƒçš„Losså›¾
                hist = pd.read_excel('Cache/history/Seq2Seq results.xlsx',
                                     sheet_name='hist')
                st.caption('è®­ç»ƒè¿‡ç¨‹çš„Losså›¾ï¼š')
                st.line_chart(hist, x_label="Epoch", y_label="Loss")
                # æ£€æŸ¥è®­ç»ƒé›†çš„è¾“å‡ºå’Œé¢„æµ‹æ˜¯å¦å­˜åœ¨
                if trainpred_exists and train_exists:
                    # å¯¼å…¥æ‰€éœ€æ•°æ®
                    y_train_pred = pd.read_excel('Cache/history/Seq2Seq results.xlsx',
                                                 sheet_name='trainpred')
                    y_train = pd.read_excel('Cache/history/Seq2Seq results.xlsx',
                                            sheet_name='train')
                    y_colums = y_train.columns
                    # å°†DataFrameè½¬æ¢ä¸ºNumpyæ•°ç»„ä»¥ä¾¿äºåç»­åˆ‡ç‰‡
                    y_train_pred = np.array(y_train_pred)
                    y_train = np.array(y_train)
                    # æ¨¡å‹æ€§èƒ½è¯„ä¼°ï¼šè®­ç»ƒé›†ä¸­çš„R2
                    r2_train = []
                    for i in range(y_train.shape[1]):
                        r2_train_i = metrics.r2_score(y_train[:, i],
                                                      y_train_pred[:, i])
                        r2_train.append(r2_train_i)
                    # ä»ç¼“å­˜ç›®å½•ä¸­è¯»å–æ ‡å‡†åŒ–å‰çš„æ•°æ®
                    data = pd.read_excel('Cache/imputed data.xlsx',
                                         sheet_name='filled')
                    # è½¬æ¢æ—¶é—´æ ¼å¼
                    data['æ—¶é—´'] = pd.to_datetime(data['æ—¶é—´'],
                                                format='%Y-%m-%d %H:%M:%S')
                    # æå–æ—¶é—´ä¿¡æ¯å¹¶å°†æ—¶é—´ä¿¡æ¯è½¬æ¢ä¸ºç´¢å¼•
                    data_index = data['æ—¶é—´']
                    data.index = data_index
                    # åˆ é™¤å¤šä½™çš„æ—¶é—´åˆ—å¹¶æå–è¾“å‡ºå˜é‡
                    data.drop(columns=['æ—¶é—´'], axis=1, inplace=True)
                    y_data = data[y_colums]
                    # ä»ç¼“å­˜ç›®å½•ä¸­åŠ è½½æ ‡å‡†åŒ–æ–¹æ³•
                    with open('Cache/scaler.pkl', 'rb') as f:
                        scaler = pickle.load(f)
                    # æ‹Ÿåˆæ ‡å‡†åŒ–æ–¹æ³•ä¸ºåæ ‡å‡†åŒ–åšå‡†å¤‡
                    y_scaled = scaler.fit_transform(y_data)
                    # å¯¹è¾“å‡ºå˜é‡çš„çœŸå®å€¼å’Œé¢„æµ‹å€¼è¿›è¡Œåæ ‡å‡†åŒ–
                    y_train = scaler.inverse_transform(y_train)
                    y_train_pred = scaler.inverse_transform(y_train_pred)
                    # æ¨¡å‹æ€§èƒ½è¯„ä¼°ï¼šè®­ç»ƒé›†ä¸­çš„MAE
                    mae_train = []
                    for i in range(y_train.shape[1]):
                        mae_train_i = metrics.mean_absolute_error(y_train[:, i], y_train_pred[:, i])
                        mae_train.append(mae_train_i)
                    # æ¨¡å‹æ€§èƒ½è¯„ä¼°ï¼šè®­ç»ƒé›†ä¸­çš„MSE
                    mse_train = []
                    for i in range(y_train.shape[1]):
                        mse_train_i = metrics.mean_squared_error(y_train[:, i], y_train_pred[:, i])
                        mse_train.append(mse_train_i)
                    # å°†æ‰€æœ‰ç»“æœè½¬æ¢ä¸ºDataFrameæ ¼å¼ä»¥ä¾¿äºå‰ç«¯å±•ç¤º
                    r2_train = pd.DataFrame(r2_train, columns=['R2'])
                    mae_train = pd.DataFrame(mae_train, columns=['MAE'])
                    mse_train = pd.DataFrame(mse_train, columns=['MSE'])
                    # æ±‡æ€»ç»“æœ
                    train_result = pd.concat([r2_train, mae_train,
                                              mse_train], axis=1)
                    train_result.index = y_colums
                    train_result = train_result.T
                    # åœ¨å‰ç«¯æ˜¾ç¤ºç»“æœ
                    st.caption('æ¨¡å‹çš„è®­ç»ƒç»“æœå¦‚ä¸‹æ‰€ç¤ºï¼š')
                    st.dataframe(train_result, use_container_width=True)
                # è‹¥è®­ç»ƒé›†çš„è¾“å‡ºå’Œé¢„æµ‹ä¸å­˜åœ¨ï¼Œåˆ™æç¤º
                else:
                    st.caption('æ¨¡å‹çš„è®­ç»ƒç»“æœå¦‚ä¸‹æ‰€ç¤ºï¼š')
                    st.info('æœªæ£€æµ‹åˆ°è®­ç»ƒç»“æœï¼', icon="â„¹ï¸")
            # è‹¥è®­ç»ƒå†å²è®°å½•ä¸å­˜åœ¨ï¼Œåˆ™æç¤º
            else:
                st.caption('è®­ç»ƒè¿‡ç¨‹çš„Losså›¾ï¼š')
                st.info('æœªæ£€æµ‹åˆ°è®­ç»ƒå†å²ï¼', icon="â„¹ï¸")
                st.caption('æ¨¡å‹çš„è®­ç»ƒç»“æœå¦‚ä¸‹æ‰€ç¤ºï¼š')
                st.info('è¯·å…ˆè®­ç»ƒæ¨¡å‹ï¼', icon="â„¹ï¸")
        # å³éƒ¨åˆ†æ˜¾ç¤ºæµ‹è¯•æ•°æ®ä¸­çš„è¾“å‡ºå˜é‡
        with col_test:
            if testpred_exists and test_exists:
                # ç»˜åˆ¶è®­ç»ƒçš„Losså›¾
                st.success("å·²æ£€æµ‹åˆ°æ¨¡å‹æµ‹è¯•ç»“æœï¼", icon="âœ…")
                st.caption('æµ‹è¯•è¿‡ç¨‹ä¸­é¢„æµ‹å€¼ä¸çœŸå®å€¼çš„å¯¹æ¯”ï¼š')
                y_test_pred = pd.read_excel('Cache/history/seq2seq results.xlsx',
                                            sheet_name='testpred')
                y_test = pd.read_excel('Cache/history/seq2seq results.xlsx',
                                       sheet_name='test')
                y_colums = y_test.columns
                y_test_pred = np.array(y_test_pred)
                y_test = np.array(y_test)
                data_dict = {}
                column_names = []
                for i in range(len(y_colums)):
                    true_name = f"çœŸå®å€¼_{i}"
                    pred_name = f"é¢„æµ‹å€¼_{i}"
                    column_names.extend([true_name, pred_name])
                    data_dict[true_name] = y_test[:, i]
                    data_dict[pred_name] = y_test_pred[:, i]
                    chart_data = pd.DataFrame(data_dict)
                st.line_chart(chart_data, x_label="æ—¶é—´", y_label="æ ‡å‡†åŒ–å€¼")
                # æ¨¡å‹æ€§èƒ½è¯„ä¼°ï¼šæµ‹è¯•é›†ä¸­çš„R2
                r2_test = []
                for i in range(y_test.shape[1]):
                    r2_test_i = metrics.r2_score(y_test[:, i], y_test_pred[:, i])
                    r2_test.append(r2_test_i)
                # ä»ç¼“å­˜ç›®å½•ä¸­è¯»å–æ ‡å‡†åŒ–å‰çš„æ•°æ®
                data = pd.read_excel('Cache/imputed data.xlsx',
                                     sheet_name='filled')
                # è½¬æ¢æ—¶é—´æ ¼å¼
                data['æ—¶é—´'] = pd.to_datetime(data['æ—¶é—´'],
                                            format='%Y-%m-%d %H:%M:%S')
                # æå–æ—¶é—´ä¿¡æ¯å¹¶å°†æ—¶é—´ä¿¡æ¯è½¬æ¢ä¸ºç´¢å¼•
                data_index = data['æ—¶é—´']
                data.index = data_index
                # åˆ é™¤å¤šä½™çš„æ—¶é—´åˆ—å¹¶æå–è¾“å‡ºå˜é‡
                data.drop(columns=['æ—¶é—´'], axis=1, inplace=True)
                y_data = data[y_colums]
                # ä»ç¼“å­˜ç›®å½•ä¸­åŠ è½½æ ‡å‡†åŒ–æ–¹æ³•
                with open('Cache/scaler.pkl', 'rb') as f:
                    scaler = pickle.load(f)
                # æ‹Ÿåˆæ ‡å‡†åŒ–æ–¹æ³•ä¸ºåæ ‡å‡†åŒ–åšå‡†å¤‡
                y_scaled = scaler.fit_transform(y_data)
                # å¯¹è¾“å‡ºå˜é‡çš„çœŸå®å€¼å’Œé¢„æµ‹å€¼è¿›è¡Œåæ ‡å‡†åŒ–
                y_test = scaler.inverse_transform(y_test)
                y_test_pred = scaler.inverse_transform(y_test_pred)
                # æ¨¡å‹æ€§èƒ½è¯„ä¼°ï¼šæµ‹è¯•é›†ä¸­çš„MAE
                mae_test = []
                for i in range(y_test.shape[1]):
                    mae_test_i = metrics.mean_absolute_error(y_test[:, i],
                                                             y_test_pred[:, i])
                    mae_test.append(mae_test_i)
                # æ¨¡å‹æ€§èƒ½è¯„ä¼°ï¼šæµ‹è¯•é›†ä¸­çš„MSE
                mse_test = []
                for i in range(y_test.shape[1]):
                    mse_test_i = metrics.mean_squared_error(y_test[:, i],
                                                            y_test_pred[:, i])
                    mse_test.append(mse_test_i)
                # å°†æ‰€æœ‰ç»“æœè½¬æ¢ä¸ºDataFrameæ ¼å¼ä»¥ä¾¿äºå‰ç«¯å±•ç¤º
                r2_test = pd.DataFrame(r2_test, columns=['R2'])
                mae_test = pd.DataFrame(mae_test, columns=['MAE'])
                mse_test = pd.DataFrame(mse_test, columns=['MSE'])
                # æ±‡æ€»ç»“æœ
                test_result = pd.concat([r2_test, mae_test,
                                         mse_test], axis=1)
                test_result.index = y_colums
                test_result = test_result.T
                # åœ¨å‰ç«¯æ˜¾ç¤ºç»“æœ
                st.caption('æ¨¡å‹çš„æµ‹è¯•ç»“æœå¦‚ä¸‹æ‰€ç¤ºï¼š')
                st.dataframe(test_result, use_container_width=True)
            # è‹¥æµ‹è¯•ç»“æœè®°å½•ä¸å­˜åœ¨ï¼Œåˆ™æç¤º
            else:
                st.caption('æµ‹è¯•è¿‡ç¨‹ä¸­é¢„æµ‹å€¼ä¸çœŸå®å€¼çš„å¯¹æ¯”ï¼š')
                st.info('æœªæ£€æµ‹åˆ°æµ‹è¯•ç»“æœï¼', icon="â„¹ï¸")
                st.caption('æ¨¡å‹çš„è®­ç»ƒç»“æœå¦‚ä¸‹æ‰€ç¤ºï¼š')
                st.info('è¯·å…ˆè®­ç»ƒæ¨¡å‹ï¼', icon="â„¹ï¸")
# ç¬¬å››éƒ¨åˆ†çš„ç¬¬ä¸€é¡µï¼šåšé¢„æµ‹
def page_41():
    # æ£€æŸ¥æ˜¯å¦å­˜åœ¨æ•°æ®ä»¥é˜²æŠ¥é”™ï¼Œè‹¥å­˜åœ¨åˆ™è¯»å–å¹¶æç¤ºæˆåŠŸï¼Œå¦åˆ™æç¤ºä¸å­˜åœ¨
    if os.path.exists('Cache/model'):
        model_exists = check_folder_empty('Cache/model')
    else:
        model_exists = False
    X_exists = check_sheet_exists(file_path='Cache/X data.xlsx',
                                  sheet_name='X')
    y_exists = check_sheet_exists(file_path='Cache/y data.xlsx',
                                  sheet_name='y')
    data_exists = check_sheet_exists(file_path='Cache/imputed data.xlsx',
                                     sheet_name='filled')
    if model_exists and X_exists and data_exists and y_exists:
        # è¯»å–è¾“å…¥æ•°æ®å¹¶æå–åˆ—å
        X = pd.read_excel('Cache/X data.xlsx', sheet_name='X')
        X['æ—¶é—´'] = pd.to_datetime(X['æ—¶é—´'], format='%Y-%m-%d %H:%M:%S')
        X_index = X['æ—¶é—´']
        X.index = X_index
        X.drop(columns=['æ—¶é—´'], axis=1, inplace=True)
        X_colums = X.columns
        # è¯»å–è¾“å‡ºæ•°æ®å¹¶æå–åˆ—å
        y = pd.read_excel('Cache/y data.xlsx', sheet_name='y')
        y['æ—¶é—´'] = pd.to_datetime(y['æ—¶é—´'], format='%Y-%m-%d %H:%M:%S')
        y_index = y['æ—¶é—´']
        y.index = y_index
        y.drop(columns=['æ—¶é—´'], axis=1, inplace=True)
        y_colums = y.columns
        st.success("å·²æ£€æµ‹åˆ°ä¸Šä¼ çš„æ•°æ®å’Œè®­ç»ƒçš„æ¨¡å‹ï¼æ‚¨å¯ä»¥è¿›è¡Œ**é¢„æµ‹**æ“ä½œï¼", icon="âœ…")
        # è¦æ±‚ç”¨æˆ·ä¸Šä¼ å¾…é¢„æµ‹æ•°æ®å¹¶é€‰æ‹©æœŸæœ›ä½¿ç”¨çš„æ¨¡å‹
        with st.form('pred_form'):
            new_file = st.file_uploader("**è¯·ä¸Šä¼ å¾…é¢„æµ‹æ•°æ®:**")
            st.caption("æ³¨ï¼šå¾…é¢„æµ‹æ•°æ®çš„åˆ—åéœ€è¦ä¸è®­ç»ƒæ¨¡å‹çš„è¾“å…¥æ•°æ®ä¿æŒä¸€è‡´ã€‚")
            model_names = os.listdir('Cache/model')
            model_option = st.selectbox("**è¯·é€‰æ‹©æ¨¡å‹ï¼š**", options=model_names)
            st.caption("æ³¨ï¼šæ¨¡å‹ä½¿ç”¨ä¸‰ç»´å¼ é‡æ ¼å¼çš„æ•°æ®è¿›è¡Œè®­ç»ƒï¼Œå¦‚æ— ç‰¹æ®Šè¦æ±‚ä¸è¦æ‰‹åŠ¨æ·»åŠ æ¨¡å‹æ–‡ä»¶ã€‚")
            submitted = st.form_submit_button('é¢„æµ‹')
    else:
        # å¸ƒå±€ï¼Œå°†æ•°æ®å’Œæ¨¡å‹çš„æ£€æŸ¥ç»“æœåˆ†æˆå·¦å³ä¸¤éƒ¨åˆ†æ˜¾ç¤º
        col_data, col_model = st.columns(2)
        with col_data:
            if not data_exists:
                st.error('æœªæ£€æµ‹åˆ°æ•°æ®ï¼', icon="ğŸš¨")
            else:
                st.success("å·²æ£€æµ‹åˆ°æ•°æ®ï¼", icon="âœ…")
        with col_model:
            if not model_exists:
                st.error('æœªæ£€æµ‹åˆ°æ¨¡å‹ï¼', icon="ğŸš¨")
            else:
                st.success("å·²æ£€æµ‹åˆ°æ¨¡å‹ï¼", icon="âœ…")
        with st.form('pred_form'):
            new_file = st.file_uploader("**è¯·ä¸Šä¼ å¾…é¢„æµ‹æ•°æ®:**", disabled=True)
            st.caption("æ³¨ï¼šå¾…é¢„æµ‹æ•°æ®çš„åˆ—åéœ€è¦ä¸è®­ç»ƒæ¨¡å‹çš„è¾“å…¥æ•°æ®ä¿æŒä¸€è‡´ã€‚")
            model_option = st.selectbox("**è¯·é€‰æ‹©æ¨¡å‹ï¼š**", options='æ— å¯ç”¨æ¨¡å‹',
                                        disabled=True)
            st.caption("æ³¨ï¼šæ¨¡å‹ä½¿ç”¨ä¸‰ç»´å¼ é‡æ ¼å¼çš„æ•°æ®è¿›è¡Œè®­ç»ƒï¼Œè¯·ä¸è¦æ‰‹åŠ¨æ·»åŠ æ¨¡å‹æ–‡ä»¶ã€‚")
            submitted = st.form_submit_button('é¢„æµ‹', disabled=True)
    with st.container(border=True):
        st.subheader('é¢„æµ‹ç»“æœ')
        st.caption("æ¨¡å‹çš„é¢„æµ‹ç»“æœå¦‚ä¸‹æ‰€ç¤ºï¼š")
        if submitted:
            if new_file is not None:
                # è½¬æ¢ä¸ºdataframeæ ¼å¼å¹¶æå–æ—¶é—´ä¿¡æ¯
                X_new = pd.read_excel(new_file)
                X_new['æ—¶é—´'] = pd.to_datetime(X_new['æ—¶é—´'],
                                             format='%Y-%m-%d %H:%M:%S')
                new_index = X_new['æ—¶é—´']
                X_new.index = new_index
                X_new.drop(columns=['æ—¶é—´'], axis=1, inplace=True)
                # ä»ç¼“å­˜ç›®å½•ä¸­è¯»å–åŸå§‹æ•°æ®å¹¶è½¬æ¢æ ¼å¼ä»¥ä¾¿äºæ“ä½œ
                data = pd.read_excel('Cache/imputed data.xlsx',
                                     sheet_name='filled')
                data['æ—¶é—´'] = pd.to_datetime(data['æ—¶é—´'],
                                            format='%Y-%m-%d %H:%M:%S')
                data_index = data['æ—¶é—´']
                data.index = data_index
                data.drop(columns=['æ—¶é—´'], axis=1, inplace=True)
                # æå–åŸå§‹æ•°æ®ä»¥ä¾¿äºåç»­å¯¹æ–°è¾“å…¥æ•°æ®æ‰§è¡Œæ ‡å‡†åŒ–
                X_raw = data[X_colums]
                y_raw = data[y_colums]
                # æå–ç”¨æˆ·æŒ‡å®šçš„åºåˆ—é•¿åº¦å¹¶è½¬æ¢ä¸ºintå½¢å¼
                seq_length = pd.read_excel('Cache/sequence length.xlsx')
                seq_length = seq_length['seq_length'].iloc[0]
                seq_length = int(seq_length)
                # æå–å†å²è¾“å…¥çš„æœ€åå‡ è¡Œçš„æ•°æ®ä½œä¸ºæ–°æ•°æ®çš„å¼€å¤´
                last_X_raw = X_raw.tail(seq_length-1)
                X_new = pd.concat([last_X_raw, X_new])
                # æ£€æŸ¥åˆ—åæ˜¯å¦ä¸€è‡´ï¼Œè‹¥ä¸ä¸€è‡´åˆ™è­¦å‘Š
                if set(X_new.columns) != set(X_raw.columns):
                    st.error("ä¸Šä¼ çš„æ–°æ•°æ®ä¸ç¬¦åˆè¦æ±‚!è¯·æ£€æŸ¥åé‡æ–°ä¸Šä¼ ï¼", icon="ğŸš¨")
                # å¦åˆ™ä»ç¼“å­˜ç›®å½•ä¸­åŠ è½½æ ‡å‡†åŒ–æ–¹æ³•å¹¶å¯¹æ–°æ•°æ®æ‰§è¡Œæ ‡å‡†åŒ–
                else:
                    with open('Cache/scaler.pkl', 'rb') as f:
                        scaler = pickle.load(f)
                    X_scaled = scaler.fit_transform(X_raw)
                    X_new_scaled = scaler.transform(X_new)
                    y_scaled = scaler.fit_transform(y_raw)
                    # æ„é€ ä¸€ä¸ªå…¨é›¶è¾“å‡ºåºåˆ—ä»¥é€‚åº”æ„é€ åºåˆ—å‡½æ•°çš„è¾“å…¥è¦æ±‚
                    y_zero = np.zeros((len(X_new_scaled), len(y_colums)))
                    # å°†æ•°æ®è½¬æ¢ä¸ºä¸‰ç»´å¼ é‡å½¢å¼
                    X_seq, y_seq = create_sequences(X_new_scaled, y_zero,
                                                    seq_length)
                    # å°†äºŒç»´è¾“å‡ºå˜é‡è½¬æ¢ä¸ºä¸‰ç»´
                    y_seq = y_seq.reshape(-1, 1, len(y_colums))
                    # å¦‚æœé€‰æ‹©LSTMæ¨¡å‹ï¼Œåˆ™å¯¼å…¥æ¨¡å‹å¹¶åšå‡ºé¢„æµ‹
                    if model_option == "LSTM.keras":
                        model = tf.keras.models.load_model('Cache/model/LSTM.keras')
                        prediction = model.predict(X_seq)
                        # å°†é¢„æµ‹ç»“æœæ‰§è¡Œåæ ‡å‡†åŒ–å¹¶è½¬æ¢ä¸ºDataFrameä»¥åœ¨å‰ç«¯æ˜¾ç¤º
                        prediction = scaler.inverse_transform(prediction)
                        prediction = pd.DataFrame(prediction, index=new_index,
                                                  columns=y_colums)
                        st.dataframe(prediction, use_container_width=True)
                    # å¦‚æœé€‰æ‹©GRUæ¨¡å‹ï¼Œåˆ™å¯¼å…¥æ¨¡å‹å¹¶åšå‡ºé¢„æµ‹
                    elif model_option == "GRU.keras":
                        model = tf.keras.models.load_model('Cache/model/GRU.keras')
                        prediction = model.predict(X_seq)
                        # å°†é¢„æµ‹ç»“æœæ‰§è¡Œåæ ‡å‡†åŒ–å¹¶è½¬æ¢ä¸ºDataFrameä»¥åœ¨å‰ç«¯æ˜¾ç¤º
                        prediction = scaler.inverse_transform(prediction)
                        prediction = pd.DataFrame(prediction, index=new_index,
                                                  columns=y_colums)
                        st.dataframe(prediction, use_container_width=True)
                    # å¦‚æœé€‰æ‹©Seq2Seqæ¨¡å‹ï¼Œåˆ™å¯¼å…¥æ¨¡å‹å¹¶åšå‡ºé¢„æµ‹
                    elif model_option == "Seq2Seq.keras":
                        model = tf.keras.models.load_model('Cache/model/Seq2Seq.keras')
                        prediction = model.predict([X_seq, y_seq])
                        prediction = prediction[:, 0, :]
                        # å°†é¢„æµ‹ç»“æœæ‰§è¡Œåæ ‡å‡†åŒ–å¹¶è½¬æ¢ä¸ºDataFrameä»¥åœ¨å‰ç«¯æ˜¾ç¤º
                        prediction = scaler.inverse_transform(prediction)
                        prediction = pd.DataFrame(prediction, index=new_index,
                                                  columns=y_colums)
                        st.dataframe(prediction, use_container_width=True)
                    # ä»¥é˜²ç”¨æˆ·æ··å…¥å…¶ä»–æ¨¡å‹æ–‡ä»¶
                    else:
                        st.error("è¯·é€‰æ‹©åˆé€‚çš„æ¨¡å‹ï¼", icon="ğŸš¨")
            else:
                st.error("è¯·ä¸Šä¼ å¾…é¢„æµ‹æ•°æ®ï¼", icon="ğŸš¨")
        else:
            st.info('è¯·ä¸Šä¼ å¾…é¢„æµ‹æ•°æ®å¹¶é€‰æ‹©åˆé€‚çš„æ¨¡å‹ï¼Œç„¶åç‚¹å‡»**é¢„æµ‹**ã€‚', icon="â„¹ï¸")
def page_42():
    # æ£€æŸ¥æ˜¯å¦å­˜åœ¨æ•°æ®ä»¥é˜²æŠ¥é”™ï¼Œè‹¥å­˜åœ¨åˆ™è¯»å–å¹¶å±•å¼€å˜é‡è¾“å…¥è¡¨å•
    if os.path.exists('Cache/model'):
        model_exists = check_folder_empty('Cache/model')
    else:
        model_exists = False
    X_exists = check_sheet_exists(file_path='Cache/X data.xlsx',
                                  sheet_name='X')
    y_exists = check_sheet_exists(file_path='Cache/y data.xlsx',
                                  sheet_name='y')
    data_exists = check_sheet_exists(file_path='Cache/imputed data.xlsx',
                                     sheet_name='filled')
    if model_exists and X_exists and data_exists and y_exists:
        # è¯»å–è¾“å…¥æ•°æ®å¹¶æå–åˆ—å
        X = pd.read_excel('Cache/X data.xlsx', sheet_name='X')
        X['æ—¶é—´'] = pd.to_datetime(X['æ—¶é—´'], format='%Y-%m-%d %H:%M:%S')
        X_index = X['æ—¶é—´']
        X.index = X_index
        X.drop(columns=['æ—¶é—´'], axis=1, inplace=True)
        X_colums = X.columns
        # è¯»å–è¾“å‡ºæ•°æ®å¹¶æå–åˆ—å
        y = pd.read_excel('Cache/y data.xlsx', sheet_name='y')
        y['æ—¶é—´'] = pd.to_datetime(y['æ—¶é—´'], format='%Y-%m-%d %H:%M:%S')
        y_index = y['æ—¶é—´']
        y.index = y_index
        y.drop(columns=['æ—¶é—´'], axis=1, inplace=True)
        y_colums = y.columns
        # ä»ç¼“å­˜ç›®å½•ä¸­è¯»å–åŸå§‹æ•°æ®å¹¶è½¬æ¢æ ¼å¼ä»¥ä¾¿äºæ“ä½œ
        data = pd.read_excel('Cache/imputed data.xlsx',
                             sheet_name='filled')
        data['æ—¶é—´'] = pd.to_datetime(data['æ—¶é—´'],
                                    format='%Y-%m-%d %H:%M:%S')
        data_index = data['æ—¶é—´']
        data.index = data_index
        data.drop(columns=['æ—¶é—´'], axis=1, inplace=True)
        # æå–åŸå§‹æ•°æ®ä»¥ä¾¿äºåç»­æ“ä½œ
        X_raw = data[X_colums]
        y_raw = data[y_colums]
        st.success("å·²æ£€æµ‹åˆ°ä¸Šä¼ çš„æ•°æ®å’Œè®­ç»ƒçš„æ¨¡å‹ï¼æ‚¨å¯ä»¥è¿›è¡Œ**é¢„æµ‹**æ“ä½œï¼", icon="âœ…")
        # è¦æ±‚ç”¨æˆ·é€‰æ‹©æœŸæœ›ä½¿ç”¨çš„æ¨¡å‹
        model_names = os.listdir('Cache/model')
        model_option = st.selectbox("**è¯·é€‰æ‹©æ¨¡å‹ï¼š**", options=model_names)
        # è®¾ç½®å˜é‡è¾“å…¥è¡¨å•
        with st.form('X_form'):
            inputs = {}
            for col in X_colums:
                min_val = X_raw[col].min()
                max_val = X_raw[col].max()
                inputs[col] = st.number_input(label=col, min_value=min_val,
                                              max_value=max_val)
            submitted = st.form_submit_button('é¢„æµ‹')
    else:
        # å¸ƒå±€ï¼Œå°†æ•°æ®å’Œæ¨¡å‹çš„æ£€æŸ¥ç»“æœåˆ†æˆå·¦å³ä¸¤éƒ¨åˆ†æ˜¾ç¤º
        col_data, col_model = st.columns(2)
        with col_data:
            if not data_exists:
                st.error('æœªæ£€æµ‹åˆ°æ•°æ®ï¼', icon="ğŸš¨")
            else:
                st.success("å·²æ£€æµ‹åˆ°æ•°æ®ï¼", icon="âœ…")
        with col_model:
            if not model_exists:
                st.error('æœªæ£€æµ‹åˆ°æ¨¡å‹ï¼', icon="ğŸš¨")
            else:
                st.success("å·²æ£€æµ‹åˆ°æ¨¡å‹ï¼", icon="âœ…")
        # å¦åˆ™ç¦ç”¨æ‰€æœ‰é€‰é¡¹å¹¶æç¤º
        model_option = st.selectbox("**è¯·é€‰æ‹©æ¨¡å‹ï¼š**", options='æ— å¯ç”¨æ¨¡å‹',
                                    disabled=True)
        with st.form('X_form'):
            st.error('æœªæ£€æµ‹åˆ°æœ‰æ•ˆæ•°æ®æˆ–æ¨¡å‹ï¼è¯·æ‚¨å®Œæˆå‰è¿°æ­¥éª¤ï¼', icon="ğŸš¨")
            submitted = st.form_submit_button('é¢„æµ‹', disabled=True)
    with st.container(border=True):
        st.subheader('é¢„æµ‹ç»“æœ')
        st.caption("æ¨¡å‹çš„é¢„æµ‹ç»“æœå¦‚ä¸‹æ‰€ç¤ºï¼š")
        if submitted:
            inputs = pd.DataFrame(inputs, index=[0])
            # æå–ç”¨æˆ·æŒ‡å®šçš„åºåˆ—é•¿åº¦å¹¶è½¬æ¢ä¸ºintå½¢å¼
            seq_length = pd.read_excel('Cache/sequence length.xlsx')
            seq_length = seq_length['seq_length'].iloc[0]
            seq_length = int(seq_length)
            # æå–å†å²è¾“å…¥çš„æœ€åå‡ è¡Œçš„æ•°æ®ä½œä¸ºæ–°æ•°æ®çš„å¼€å¤´
            last_X_raw = X_raw.tail(seq_length-1)
            X_new = pd.concat([last_X_raw, inputs])
            # å¦åˆ™ä»ç¼“å­˜ç›®å½•ä¸­åŠ è½½æ ‡å‡†åŒ–æ–¹æ³•å¹¶å¯¹æ–°æ•°æ®æ‰§è¡Œæ ‡å‡†åŒ–
            with open('Cache/scaler.pkl', 'rb') as f:
                scaler = pickle.load(f)
            X_scaled = scaler.fit_transform(X_raw)
            X_new_scaled = scaler.transform(X_new)
            y_scaled = scaler.fit_transform(y_raw)
            # æ„é€ ä¸€ä¸ªå…¨é›¶è¾“å‡ºåºåˆ—ä»¥é€‚åº”æ„é€ åºåˆ—å‡½æ•°çš„è¾“å…¥è¦æ±‚
            y_zero = np.zeros((len(X_new_scaled), len(y_colums)))
            # å°†æ•°æ®è½¬æ¢ä¸ºä¸‰ç»´å¼ é‡å½¢å¼
            X_seq, y_seq = create_sequences(X_new_scaled, y_zero, seq_length)
            # å°†äºŒç»´è¾“å‡ºå˜é‡è½¬æ¢ä¸ºä¸‰ç»´
            y_seq = y_seq.reshape(-1, 1, len(y_colums))
            # å¦‚æœé€‰æ‹©LSTMæ¨¡å‹ï¼Œåˆ™å¯¼å…¥æ¨¡å‹å¹¶åšå‡ºé¢„æµ‹
            if model_option == "LSTM.keras":
                model = tf.keras.models.load_model('Cache/model/LSTM.keras')
                prediction = model.predict(X_seq)
                # å°†é¢„æµ‹ç»“æœæ‰§è¡Œåæ ‡å‡†åŒ–å¹¶è½¬æ¢ä¸ºDataFrameä»¥åœ¨å‰ç«¯æ˜¾ç¤º
                prediction = scaler.inverse_transform(prediction)
                prediction = pd.DataFrame(prediction, columns=y_colums)
                st.dataframe(prediction, hide_index=True,
                             use_container_width=True)
            # å¦‚æœé€‰æ‹©GRUæ¨¡å‹ï¼Œåˆ™å¯¼å…¥æ¨¡å‹å¹¶åšå‡ºé¢„æµ‹
            elif model_option == "GRU.keras":
                model = tf.keras.models.load_model('Cache/model/GRU.keras')
                prediction = model.predict(X_seq)
                # å°†é¢„æµ‹ç»“æœæ‰§è¡Œåæ ‡å‡†åŒ–å¹¶è½¬æ¢ä¸ºDataFrameä»¥åœ¨å‰ç«¯æ˜¾ç¤º
                prediction = scaler.inverse_transform(prediction)
                prediction = pd.DataFrame(prediction, columns=y_colums)
                st.dataframe(prediction, hide_index=True,
                             use_container_width=True)
            # å¦‚æœé€‰æ‹©Seq2Seqæ¨¡å‹ï¼Œåˆ™å¯¼å…¥æ¨¡å‹å¹¶åšå‡ºé¢„æµ‹
            elif model_option == "Seq2Seq.keras":
                model = tf.keras.models.load_model('Cache/model/Seq2Seq.keras')
                prediction = model.predict([X_seq, y_seq])
                prediction = prediction[:, 0, :]
                # å°†é¢„æµ‹ç»“æœæ‰§è¡Œåæ ‡å‡†åŒ–å¹¶è½¬æ¢ä¸ºDataFrameä»¥åœ¨å‰ç«¯æ˜¾ç¤º
                prediction = scaler.inverse_transform(prediction)
                prediction = pd.DataFrame(prediction, columns=y_colums)
                st.dataframe(prediction, hide_index=True,
                             use_container_width=True)
            # ä»¥é˜²ç”¨æˆ·æ··å…¥å…¶ä»–æ¨¡å‹æ–‡ä»¶
            else:
                st.error("è¯·é€‰æ‹©åˆé€‚çš„æ¨¡å‹ï¼", icon="ğŸš¨")
        else:
            st.info('è¯·é€‰æ‹©åˆé€‚çš„æ¨¡å‹å¹¶è¾“å…¥ç›¸å…³å˜é‡å€¼ï¼Œç„¶åç‚¹å‡»**é¢„æµ‹**ã€‚', icon="â„¹ï¸")
# ä¾§è¾¹æ å¯¼èˆª
pages = {"é¡¹ç›®ä»‹ç»": [st.Page(page_11, title="ä½¿ç”¨å‰å¿…è¯»")],
         "æ—¶é—´åºåˆ—æ•°æ®": [st.Page(page_21, title="æ•°æ®ä¸Šä¼ "),
                    st.Page(page_22, title="æ•°æ®å¤„ç†"),
                    st.Page(page_23, title="ç‰¹å¾é€‰æ‹©")],
         "æ·±åº¦å­¦ä¹ æ¨¡å‹": [st.Page(page_31, title="æ—¶é—´åºåˆ—åˆ’åˆ†"),
                    st.Page(page_32, title="é•¿çŸ­æœŸè®°å¿†ç¥ç»ç½‘ç»œ"),
                    st.Page(page_33, title="é—¨æ§å¾ªç¯å•å…ƒ"),
                    st.Page(page_34, title="åºåˆ—åˆ°åºåˆ—æ¨¡å‹")],
         "æ¨¡å‹åº”ç”¨": [st.Page(page_41, title="å¤šæ­¥é¢„æµ‹"),
                  st.Page(page_42, title="å•æ­¥é¢„æµ‹")]}
pg = st.navigation(pages)
pg.run()